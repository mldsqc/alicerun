{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import date\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data_preparing import sessions_download, read_db_paths, df_tasks_prepare, emotions_habits_df_prepare, \\\n",
    "    tasks_read_metrics, tasks_motivation\n",
    "from data_preparing import number_tasks_per_day,number_tasks_per_day_per_task, number_hard_tasks_per_m\n",
    "from data_preparing import check_goals_difficulty, amount_tasks_done_life_areas, tasks_done_per_month\n",
    "from data_preparing import amount_complited_tasks_permonth, amount_complited_tasks_per_list_month, \\\n",
    "    check_error_rate_predicting_ttc,amount_new_tasks_per_day\n",
    "from data_preparing import after_metric_ttc\n",
    "\n",
    "from data_preparing import *\n",
    "from bot_answers_analysis import load_emotions_habits_values\n",
    "from recommendation_ML import *\n",
    "\n",
    "from data_preparing import memory_usage\n",
    "\n",
    "# import\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DB_ADASH1, DB_TODO, DB_ACTWATCH, DB_GADGETBRIDGE, DB_ADASH2, DB_ADASH3, DB_ADASH4, DB_EMOTIONS_TEST = read_db_paths()\n",
    "\n",
    "\n",
    "df_sessions = pd.DataFrame(sessions_download())\n",
    "df_sessions.rename(columns={'description': 'subject'}, inplace=True)\n",
    "\n",
    "\n",
    "df_sessions=df_sessions[df_sessions.duration>0]\n",
    "# df_sessions\n",
    "\n",
    "\n",
    "df_tasks, df_joined = df_tasks_prepare(DB_TODO)\n",
    "# df_tasks\n",
    "# df_joined\n",
    "\n",
    "\n",
    "df_tasks_2 = tasks_read_metrics(df_tasks, df_joined)\n",
    "# df_tasks_2\n",
    "\n",
    "\n",
    "df_tasks_3 = tasks_motivation(df_tasks_2)\n",
    "# df_tasks_3\n",
    "\n",
    "\n",
    "df_emotions, df_habits, df_emotions1 = emotions_habits_df_prepare()\n",
    "\n",
    "\n",
    "df_tasks_3_t = after_features_assumpted(df=df_sessions, df1=df_tasks_3, df_tasks_3=df_tasks_3,\n",
    "                                        df_emotions1=df_emotions1)\n",
    "\n",
    "\n",
    "# memory_usage()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_tasks_3_t.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_emotions1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_sessions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def floor_dt(dt, interval=10):\n",
    "    \"\"\"rounding datetime column to 10 min intervals\"\"\"\n",
    "\n",
    "    replace = (dt.minute // interval) * interval\n",
    "    return dt.replace(minute=replace, second=0, microsecond=0)\n",
    "\n",
    "# DB_EMOTIONS_TEST = read_db_paths()[-1]\n",
    "emotions_habits = pd.read_csv(DB_EMOTIONS_TEST)\n",
    "emotions_values, habits_values, emotions_and_habits_values = load_emotions_habits_values()\n",
    "# emotions_habits\n",
    "\n",
    "emotions_habits['datetime'] = emotions_habits.date.astype('str') + ' ' + emotions_habits.time.astype('str')\n",
    "emotions_habits['datetime'] = emotions_habits['datetime'].astype('datetime64')\n",
    "\n",
    "emotions_habits.drop(['date', 'time'], axis=1, inplace=True)\n",
    "emotions_habits['datetime_rnd'] = emotions_habits.datetime.apply(floor_dt)\n",
    "emotions_habits['emo_hab'] = np.where(emotions_habits['act'].isin(emotions_values.keys()), 0, 1)\n",
    "\n",
    "emotions_habits = emotions_habits.groupby('datetime_rnd')['act'].agg(list).reset_index()  # .iloc[1,:]\n",
    "\n",
    "\n",
    "# GENERATION get dummies from list of emotions (act column) grouped by 10min periods\n",
    "emotions_habits = emotions_habits.join(emotions_habits['act'].str.join('|').str.get_dummies())\n",
    "\n",
    "emotions_habits.datetime_rnd = emotions_habits.datetime_rnd.dt.strftime('%Y-%m-%d %H:%M:%S')#.set_index('datetime_rnd')\n",
    "emotions_habits = emotions_habits.drop('act', axis=1)\n",
    "emotions_habits.set_index('datetime_rnd', inplace=True)\n",
    "# print(emotions_habits)\n",
    "\n",
    "\n",
    "def merge_close_timeslots(df):\n",
    "    \"\"\"MERGING THE MOST CLOSE REGISTERED ROWS-TIMESLOTS FOR EMOTIONS HABITS DF\"\"\"\n",
    "    list_of_dd = df.index.to_list()\n",
    "    # print(list_of_dd)\n",
    "\n",
    "    list_of_id_todrop = []\n",
    "    indd=0\n",
    "\n",
    "    for kk in list_of_dd:\n",
    "        if indd+2<=len(list_of_dd):\n",
    "            deltaa=abs(pd.to_datetime(kk) - pd.to_datetime(list_of_dd[indd+1]))\n",
    "            if deltaa < pd.Timedelta('1 hours'):\n",
    "                # print(df.loc[kk])\n",
    "                # print('---')\n",
    "                df.loc[kk] = df.loc[kk] + df.loc[list_of_dd[indd+1]]\n",
    "                list_of_id_todrop.append(list_of_dd[indd+1])\n",
    "\n",
    "                # print(df.loc[list_of_dd[indd+1]])\n",
    "                # print('---')\n",
    "                #\n",
    "                # print(df.loc[kk])\n",
    "                # print(indd, kk, list_of_dd[indd+1]) # for checking\n",
    "            indd+=1\n",
    "    for ki in list_of_id_todrop:\n",
    "        df.drop(ki, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "emotions_habits = merge_close_timeslots(emotions_habits)\n",
    "\n",
    "\n",
    "# MAKING DF FROM SESSIONS\n",
    "def group_by_period(dff):\n",
    "        dff['for_count']=dff['subject'].map(type) == str\n",
    "        #number of sessions per day\n",
    "        number_sessions_per_day = dff.groupby(pd.Grouper(key='start', axis=0,\n",
    "                                             freq='H')).agg({'for_count':sum}).reset_index()\n",
    "\n",
    "        #amount of hours tracked per day\n",
    "        amount_of_hours_tracked_per_day = dff.groupby([pd.Grouper(key='start', axis=0,\n",
    "                                             freq='H'),]).agg({'duration':sum})/ 3600\n",
    "        # number_sessions_per_day.start = number_sessions_per_day.start.astype(str)\n",
    "\n",
    "        out=pd.concat([number_sessions_per_day.set_index('start'),amount_of_hours_tracked_per_day], axis=1).reset_index()\n",
    "        return out\n",
    "\n",
    "df_sessions_for_good = group_by_period(df_sessions)\n",
    "df_sessions_for_good = df_sessions_for_good.rename(columns={'for_count':'amount_sessions', 'start':'datetime_rnd'})\n",
    "df_sessions_for_good = df_sessions_for_good.drop(columns={'duration'})\n",
    "\n",
    "# FROM HERE WE ARE TAKING NUMBER OF SESSIONS IN SPECIFIC TIMESLOTS\n",
    "df_sessions_for_good.datetime_rnd = df_sessions_for_good.datetime_rnd.dt.strftime('%Y-%m-%d %H:%M:%S')#.set_index('datetime_rnd')\n",
    "\n",
    "df_sessions_for_good.set_index('datetime_rnd', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# DETECTING NOT REGISTERED TIME OF WHEN TIME WAS DONE\n",
    "\n",
    "df_sessions1 = df_sessions.groupby(['subject']).agg({'stop': max}).reset_index()\n",
    "\n",
    "df_tasks_3_t_ = df_tasks_3_t.groupby(['completed_datetime']).agg({'subject':\"value_counts\"})\n",
    "# df_tasks_3_t_\n",
    "\n",
    "tasks_done_per_days =  df_tasks_3_t_.groupby(['completed_datetime']).agg({'subject':sum}).reset_index()\n",
    "# tasks_done_per_days\n",
    "\n",
    "# ADDING HOURS MINUTES TO TASK_DONE DF BASED ON TIMESTAMPS IN EMOTIONS DF\n",
    "import random\n",
    "def add_random_hours_min(k):\n",
    "    # detecting timeslots in emotions habits df to JOIN on them later\n",
    "    list_of_timeslots = emotions_habits.reset_index().datetime_rnd.astype('datetime64').dt.strftime(\"%H:%M:%S\").unique()\n",
    "    return k +' '+ np.random.choice(list_of_timeslots)\n",
    "\n",
    "tasks_done_per_days.completed_datetime = tasks_done_per_days.completed_datetime.astype(str).apply(lambda x:\n",
    "                                                                                                add_random_hours_min(x))\n",
    "tasks_done_per_days.completed_datetime = tasks_done_per_days.completed_datetime.astype('datetime64')\n",
    "tasks_done_per_days = tasks_done_per_days.rename(columns={'completed_datetime':'datetime_rnd','subject':'tasks_done'})\n",
    "tasks_done_per_days = tasks_done_per_days.set_index('datetime_rnd')\n",
    "\n",
    "\n",
    "def find_nearest_date(df1, df_emo):\n",
    "    \"\"\"\n",
    "    finding nearest date in df_emo and write it to df1\n",
    "\n",
    "    #TODO too many times reseting the index. but now pipeline used in inner functions\n",
    "\n",
    "    :param df1: df of sessions with generated hours minutes\n",
    "    :param df_emo: emotions habits dataframe\n",
    "    :return: df with changed time\n",
    "    \"\"\"\n",
    "\n",
    "    df1 = df1.reset_index()\n",
    "    df_emo = df_emo.reset_index()\n",
    "    df1.datetime_rnd = df1.datetime_rnd.astype('datetime64')\n",
    "    df_emo.datetime_rnd = df_emo.datetime_rnd.astype('datetime64')\n",
    "\n",
    "    df2 = df1.copy() #CONTroVERSIVE\n",
    "\n",
    "    # return df1.datetime_rnd\n",
    "    for i in df2.datetime_rnd:\n",
    "        # print(i)\n",
    "        minidx_ = abs(i - df_emo['datetime_rnd']).argmin()\n",
    "        delta = abs(i - df_emo.loc[minidx_,'datetime_rnd'])\n",
    "        # print(i, df_emo.loc[[minidx_]]['datetime_rnd'] , delta, delta/pd.Timedelta('1 hour'))\n",
    "\n",
    "        if delta/pd.Timedelta('1 hour') < 5:\n",
    "            index = df2.index[df2.datetime_rnd==i]\n",
    "            # print(df1.loc[index, 'datetime_rnd'])\n",
    "            # print('BEFORE',df_emo.loc[minidx_,'datetime_rnd'])\n",
    "            df2.loc[index, 'datetime_rnd'] = df_emo.loc[minidx_,'datetime_rnd']\n",
    "            # print('CHANGE', df1.loc[index, 'datetime_rnd'])\n",
    "\n",
    "        # print()\n",
    "        # print(df_emo.loc[[minidx_]])\n",
    "    return df2\n",
    "\n",
    "\n",
    "\n",
    "df_sessions_for_good_ = find_nearest_date(df_sessions_for_good, emotions_habits)\n",
    "tasks_done_per_days_ = find_nearest_date(tasks_done_per_days, emotions_habits)\n",
    "\n",
    "#summing up duplicates\n",
    "df_sessions_for_good_ = df_sessions_for_good_.reset_index().groupby('datetime_rnd').agg({'amount_sessions': sum})\n",
    "\n",
    "#just test\n",
    "# df_sessions_for_good_[df_sessions_for_good_.datetime_rnd=='2022-08-09 10:50:00']\n",
    "# df_sessions_for_good_[df_sessions_for_good_.amount_sessions>0]\n",
    "\n",
    "\n",
    "# df_sessions_for_good_ = df_sessions_for_good_.set_index('datetime_rnd')\n",
    "# tasks_done_per_days_ = tasks_done_per_days_.set_index('datetime_rnd')\n",
    "\n",
    "\n",
    "\n",
    "emotions_habits_t = emotions_habits.reset_index().copy()\n",
    "emotions_habits_t.datetime_rnd = emotions_habits_t.datetime_rnd.astype(str)\n",
    "\n",
    "tasks_done_per_days_.datetime_rnd = tasks_done_per_days_.datetime_rnd.astype(str)\n",
    "# emotions_habits_t\n",
    "\n",
    "df_sessions_for_good_t = df_sessions_for_good_.reset_index().copy()\n",
    "df_sessions_for_good_t.datetime_rnd = df_sessions_for_good_t.datetime_rnd.astype(str)\n",
    "\n",
    "#MERGING ALL together\n",
    "df_final_ = emotions_habits_t.merge(tasks_done_per_days_, how='left', on='datetime_rnd')\n",
    "df_final = df_final_.merge(df_sessions_for_good_t, how='left', on='datetime_rnd')\n",
    "\n",
    "\n",
    "# df_final_ = pd.concat([emotions_habits, tasks_done_per_days_], axis = 1)\n",
    "# df_final = pd.concat([df_final_, df_sessions_for_good_], axis = 1)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_sessions1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "emotions_habits.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_sessions_for_good[df_sessions_for_good.amount_sessions>0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "emotions_habits"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tasks_done_per_days_\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# show distribution of hours when tasks were done in toggl data\n",
    "df_sessions1.stop.dt.strftime(\"%H\").astype(int).plot(kind=\"kde\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## POSSIBLE TO DRAW HOW SCHEDULE,  WORKHOURS  DEPENDS ON DONE TASKS\n",
    "\n",
    "what work hours are more productive and how are they changing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_sessions1.stop.dt.strftime(\"%M\").astype(int).plot(kind=\"kde\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.to_datetime(str(random.randint(11, 22))+':'+str(random.randint(10, 43)) +':'+'00').strftime\\\n",
    "        (\"%H:%M:%S\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# FROM HERE WE ARE TAKING NUMBER OF SESSIONS IN SPECIFIC TIMESLOTS\n",
    "#hours-minutes are not generated but summed by hours\n",
    "df_sessions_for_good_ #.set_index('datetime_rnd', inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# MAIN DF WITH EMOTIONS HABITS PER TIMESLOTS\n",
    "emotions_habits"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tasks_done_per_days_\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "df_final#[(df_final.amount_sessions.notna()) & (df_final.tasks_done.notna())]#.index # &  & df_final['5-7'].notna())\n",
    "# df_final.tasks_done.notna()\n",
    "#  df_final.tasks_done.notna()]  #\n",
    "# .amount_sessions.value_counts()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def number_done_tasks_per_d():\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "\n",
    "    number_done_tasks_per_day = number_tasks_per_day(df_tasks_3_t).iloc[:,:1].reset_index()\n",
    "\n",
    "    left_range = number_done_tasks_per_day.completed_datetime.max() + relativedelta(months=-1)\n",
    "    right_range = number_done_tasks_per_day.completed_datetime.max()\n",
    "\n",
    "    fig = px.line(number_done_tasks_per_day, x=\"completed_datetime\",y=[number_done_tasks_per_day.subject,\n",
    "                                                                       number_done_tasks_per_day.subject.rolling(30).mean()],\n",
    "                  color_discrete_sequence=px.colors.sequential.Plasma_r,\n",
    "                  template=\"plotly_dark\", line_shape='spline',\n",
    "                  range_x=(left_range,right_range),title='NUMBER_DONE_TASKS_PER_DAY')\n",
    "\n",
    "    fig.update_layout(\n",
    "            autosize=False,\n",
    "            height=500,\n",
    "            width=600,showlegend=False,\n",
    "                # plot_bgcolor=\"white\",\n",
    "                margin=dict(t=35,l=15,b=15,r=15),\n",
    "                xaxis_title='NUMBER_DONE_TASKS_PER_DAY',\n",
    "                yaxis_title=''\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "number_done_tasks_per_d()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def working_time_stats():\n",
    "    \"\"\"plotting 3 stats on everyday working sessions\n",
    "    number of sessions per day\n",
    "    amount of hours tracked per day\n",
    "    average for 30days for daily workhours\n",
    "    scaling for last month\n",
    "    \"\"\"\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "\n",
    "    df_sessions['for_count']=df_sessions['subject'].map(type) == str\n",
    "    #number of sessions per day\n",
    "    number_sessions_per_day = df_sessions.groupby(pd.Grouper(key='start', axis=0,\n",
    "                                         freq='D')).agg({'for_count':sum}).reset_index()\n",
    "\n",
    "    #amount of hours tracked per day\n",
    "    amount_of_hours_tracked_per_day = df_sessions.groupby([pd.Grouper(key='start', axis=0,\n",
    "                                         freq='D'),]).agg({'duration':sum})/ 3600\n",
    "    # number_sessions_per_day.start = number_sessions_per_day.start.astype(str)\n",
    "\n",
    "    out=pd.concat([number_sessions_per_day.set_index('start'),amount_of_hours_tracked_per_day], axis=1).reset_index()\n",
    "    print(out)\n",
    "\n",
    "    left_range = out.start.max() + relativedelta(months=-1)\n",
    "    right_range = out.start.max()\n",
    "\n",
    "    fig19 = px.line(out, x=out.start, y=[out.for_count, out.duration, out.duration.rolling(30).mean()],\n",
    "                            line_shape = 'spline',\n",
    "                            title='sessions_info',\n",
    "                            color_discrete_sequence=px.colors.sequential.Plasma_r,\n",
    "                            template=\"plotly_dark\", range_x=(left_range,right_range)\n",
    "                     )\n",
    "    fig19.update_layout(\n",
    "            autosize=False,\n",
    "            height=600,\n",
    "            width=800,#showlegend=False,\n",
    "                margin=dict(t=35,l=15,b=15,r=15),\n",
    "                xaxis_title='',\n",
    "                yaxis_title=''\n",
    "        )\n",
    "\n",
    "    fig19.show()\n",
    "\n",
    "\n",
    "working_time_stats()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def  life_areas_balance_count(df_tasks_3_t, df_habits, period='W'):\n",
    "    \"\"\"count habits and tasks done by time period grouping by life_areas\n",
    "        not counting summary values of habbits, just counting amount of acts \"\"\"\n",
    "    from shapely.geometry import MultiPoint\n",
    "    habits_list_for_check = {\n",
    "    'PHYSICAL': ['slept_GOOD', 'cold shower', '10 pushups everyday', 'big physical activity',\n",
    "                              'over_eated', 'fastfood', 'cafe'],\n",
    "\n",
    "    'FUN_RECREATION': ['traveled', 'drugs', 'jrk', 'porn', 'too much movies',\n",
    "    'too much youtube', 'too much social media', 'too much news', 'any pain',\n",
    "    '+youtubed', 'film', 'tvshow', 'cinema', 'gaming'],\n",
    "\n",
    "    'INTELECTUAL': ['made smth for selfefficiency',\n",
    "    'how many info i consumed vs generated out in the world', 'running on plans feeling', 'psycho practices',\n",
    "    '5 minute journal', 'meditation', 'look inside 4 feelings on whole life', 'bucket list',\n",
    "    'wish list', 'reading', 'studing', 'chess', 'ankicards', 'languages'],\n",
    "\n",
    "    'LOVE ROMANCE SEX': ['sex','new sex partner', 'new sex practices'],\n",
    "\n",
    "    'PARTNER': ['harmony_pleasurefull', 'critiqued_by_HER',\n",
    "    'critiqued_by_ME', 'arguing', 'work thru complicated situations', 'common goals completion'],\n",
    "\n",
    "    'SOCIAL FRIENDS': ['social offline', 'new people', 'old_friends'],\n",
    "\n",
    "    'FINANCIAL': ['encreased income','financial reduce costs', 'investing']\n",
    "    }\n",
    "\n",
    "    #done tasks by life_areas\n",
    "    df_done_tasks_by_lifearea = amount_tasks_done_life_areas(df_tasks_3_t, time_period=period).iloc[:,:1].reset_index()\\\n",
    "        .rename(columns={'completed_datetime':'datetime_rnd','subject':'act'})\n",
    "    # df_done_tasks_by_lifearea\n",
    "\n",
    "\n",
    "    df_habits['life_area'] = ''\n",
    "    for k in df_habits.act.unique(): # adding column life_area to each acts responsively\n",
    "        for i in habits_list_for_check.keys():\n",
    "            if k in habits_list_for_check[i]:\n",
    "                df_habits.loc[df_habits['act'] == k,'life_area'] = i\n",
    "    df_habits = df_habits[df_habits.life_area!=''] #dropping rows which arent in dictionary\n",
    "\n",
    "    #grouping by period of time and life area and counting similar acts\n",
    "    df_habits1 = df_habits.groupby([pd.Grouper(key='datetime_rnd', axis=0,\n",
    "                                     freq=period), df_habits.life_area]).agg({'act':'value_counts'})\n",
    "\n",
    "    df_habits1.index.names = [\"datetime_rnd\", \"life_area\", \"acts\"] # renaming duplicate columns\n",
    "    df_habits1 = df_habits1.reset_index().groupby(['datetime_rnd', 'life_area']).agg({'act':sum}).reset_index()\n",
    "    # print(df_habits)\n",
    "\n",
    "    out = pd.concat([df_done_tasks_by_lifearea, df_habits1])\n",
    "    out = out.groupby([\"datetime_rnd\",\"life_area\"], as_index=False).sum()\n",
    "\n",
    "\n",
    "    # making mean values for year\n",
    "    out_mean_year = out.groupby([pd.Grouper(key='datetime_rnd', axis=0,\n",
    "                                     freq='Y'), out.life_area]).agg({'act':'mean'}).reset_index()\n",
    "    # out_mean_year.rename(columns={'act': 'act_mean'}, inplace=True)\n",
    "    out_mean_year.act_mean = out_mean_year.act.round(0).astype(int)\n",
    "    out_mean_year.datetime_rnd = out.datetime_rnd.mean()\n",
    "    out['model'] = 'daily'\n",
    "    out_mean_year['model'] = 'year_mean'\n",
    "    # print(pd.concat([out, out_mean_year], axis=0))\n",
    "    # out = out.set_index('life_area').join(out_mean_year.set_index('life_area')).reset_index()\n",
    "\n",
    "    out2=pd.DataFrame()\n",
    "    temp = out_mean_year.copy() # df to copy on all unique dates to show year mean values\n",
    "                                                # constantly\n",
    "    # print(out.life_area.unique())\n",
    "    for ik in out.datetime_rnd.unique():\n",
    "        temp.datetime_rnd = ik\n",
    "        out2 = pd.concat([out2,temp], axis=0)\n",
    "\n",
    "    # for il in out.act.unique():\n",
    "\n",
    "\n",
    "\n",
    "    out=pd.concat([out, out2], axis=0)\n",
    "\n",
    "    #preparing df for plotting\n",
    "    out['datetime_rnd'] = out['datetime_rnd'].astype(str)\n",
    "    out.datetime_rnd= out.datetime_rnd.astype('datetime64').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    out.drop(out[out.life_area.isin(['FUNRECREATION', 'INTELLECTUAL'])].index, inplace=True)\n",
    "\n",
    "    out = out.sort_values(by=['act', 'life_area'], ascending=True)\n",
    "\n",
    "    out['act']=out['act']+0.3\n",
    "    max_r = out.act.max()\n",
    "\n",
    "    # https://stackoverflow.com/questions/73624867/how-to-calculate-area-of-a-radar-chart-in-plotly-matplotlib\n",
    "    # compare areas of two plots\n",
    "    # convert theta to be in radians\n",
    "    out[\"theta_n\"] = pd.factorize(out[\"life_area\"])[0]\n",
    "    out[\"theta_radian\"] = (out[\"theta_n\"] / (out[\"theta_n\"].max() + 1)) * 2 * np.pi\n",
    "    # work out x,y co-ordinates\n",
    "    out[\"x\"] = np.cos(out[\"theta_radian\"]) * out[\"act\"]\n",
    "    out[\"y\"] = np.sin(out[\"theta_radian\"]) * out[\"act\"]\n",
    "    df_a = out.groupby(\"model\").apply( lambda d: MultiPoint(list(zip(d[\"x\"], d[\"y\"]))).convex_hull.area)\n",
    "    # print(df_a)\n",
    "    print(out)\n",
    "\n",
    "    fig12 = px.line_polar(out[out.datetime_rnd>'2022-07-14'],\n",
    "                        r='act',\n",
    "                        theta='life_area', color=\"model\",\n",
    "                        line_close=True,  line_shape = 'spline',\n",
    "                        animation_frame = 'datetime_rnd',\n",
    "                        title='Emotions',\n",
    "                        range_r=[0,max_r],\n",
    "                        start_angle=270,\n",
    "                        color_discrete_sequence=px.colors.sequential.Plasma_r,\n",
    "                        template=\"plotly_dark\"\n",
    "                 )\n",
    "\n",
    "\n",
    "\n",
    "    fig12.update_layout(\n",
    "        autosize=False,\n",
    "        height=500,\n",
    "        width=600\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    fig12.show()\n",
    "    # pyo.plot(fig)\n",
    "    fig12.write_html('plot_life_areas_balance.html')\n",
    "\n",
    "\n",
    "life_areas_balance_count(df_tasks_3_t, df_habits, period='W')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ideas_sparks(df_tasks_3_t):\n",
    "    \"\"\"#creativity - ideas sparks\n",
    "    amount of new ideas-tasks written down on TODO app\"\"\"\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "    df_new_tasks_pday = amount_new_tasks_per_day(df_tasks_3_t)\n",
    "    left_range = df_new_tasks_pday.created_datetime.max() + relativedelta(months=-1)\n",
    "    right_range = df_new_tasks_pday.created_datetime.max()\n",
    "    fig16 = px.line(df_new_tasks_pday, x=\"created_datetime\",y=[df_new_tasks_pday.subject,\n",
    "                                                                           df_new_tasks_pday.subject.rolling(30).mean()],\n",
    "                    # color=[\"red\", \"goldenrod\", \"#00D\"],\n",
    "                      color_discrete_sequence=px.colors.qualitative.G10, #px.colors.sequential.Plasma_r,\n",
    "                      template=\"plotly_dark\", line_shape='spline',\n",
    "                      range_x=(left_range,right_range) , title='NUMBER_DONE_TASKS_PER_DAY'\n",
    "                    )\n",
    "\n",
    "    fig16.update_layout(\n",
    "                autosize=False,\n",
    "                height=400,\n",
    "                width=500,\n",
    "                showlegend=False,\n",
    "                # plot_bgcolor=\"white\",\n",
    "                margin=dict(t=35,l=15,b=15,r=15),\n",
    "                xaxis_title='',\n",
    "                yaxis_title=''\n",
    "        )\n",
    "    fig16.update_traces(line=dict(width=1.5), opacity=.9,)\n",
    "    # fig16.update_xaxes(visible=False)\n",
    "    # fig16.update_yaxes(visible=False)#, fixedrange=True\n",
    "    fig16.show()\n",
    "\n",
    "ideas_sparks(df_tasks_3_t)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TODO plot and see trend, timewindows????\n",
    "#in how many times amount of not underrated tasks (predicted TTC right)\n",
    "# more than amount of predicted badly tasks\n",
    "\n",
    "df_tasks_3_t[df_tasks_3_t.underrated==False].underrated.count()/df_tasks_3_t[df_tasks_3_t.underrated==True].underrated.count()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def cold_start_ml(df_tasks_3_t):\n",
    "\n",
    "    most_forgotten = []\n",
    "    most_active = []\n",
    "    # recommend tasks from most forgotten areas\n",
    "    for iii in count_balance_of_life_areas_tasks_habits(df_tasks_3_t)[0]:\n",
    "        if df_tasks_3_t[df_tasks_3_t['life_area'] == iii].shape[0] !=0:\n",
    "            # print(iii)\n",
    "            # print(' ------  ')\n",
    "            # print(return_tasks_list_by(df_tasks_3_t, iii).subject.sample())\n",
    "            most_forgotten.append('----TOP from ' + str(iii) + ':' )\n",
    "            # print('TOP from ' + str(iii) + ':' )\n",
    "            # print(return_tasks_list_by(df_tasks_3_t, iii).subject.head(3))\n",
    "            if type((return_tasks_list_by(df_tasks_3_t, iii)))==tuple:\n",
    "                for kk in return_tasks_list_by(df_tasks_3_t, iii):\n",
    "                    # print(k)\n",
    "                    most_forgotten.extend(kk.to_list())\n",
    "                    # most_forgotten += \"\\n\"\n",
    "                # print(most_forgotten)\n",
    "\n",
    "            else:\n",
    "                for ki in return_tasks_list_by(df_tasks_3_t, iii).subject.values:\n",
    "                    # print(k)\n",
    "                    most_forgotten.append(ki)\n",
    "                    # most_forgotten += \"\\n\"\n",
    "                # print(most_forgotten)\n",
    "\n",
    "\n",
    "        # recommend tasks from most active areas\n",
    "    for iii in count_balance_of_life_areas_tasks_habits(df_tasks_3_t)[1]:\n",
    "        if df_tasks_3_t[df_tasks_3_t['life_area'] == iii].shape[0] !=0:\n",
    "\n",
    "            # print(iii)\n",
    "            # print(' ------  ')\n",
    "            most_active.append('-----TOP from ' + str(iii) + ':')\n",
    "            # most_active += \"\\n\".join(return_tasks_list_by(df_tasks_3_t, iii))\n",
    "            # most_active += \"\\n\"\n",
    "            # print(most_active)\n",
    "            if len(return_tasks_list_by(df_tasks_3_t, iii))!=0:\n",
    "                if type((return_tasks_list_by(df_tasks_3_t, iii)))==tuple:\n",
    "                    for k in return_tasks_list_by(df_tasks_3_t, iii):\n",
    "                        most_active.extend(k.to_list())\n",
    "                        # print(most_active)\n",
    "                        # print(k)\n",
    "                # else:\n",
    "                #     for ke in return_tasks_list_by(df_tasks_3_t, iii).subject.values:\n",
    "                #         # print(k)\n",
    "                #         most_forgotten.append(ke)\n",
    "\n",
    "    return most_forgotten,most_active\n",
    "\n",
    "cold_start_ml(df_tasks_3_t)[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cold_start_ml(df_tasks_3_t)[0]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_sessions[df_sessions.duration<0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "from gcal import *\n",
    "from gcsa.reminders import EmailReminder, PopupReminder\n",
    "\n",
    "\n",
    "\n",
    "def add_popup_reminder(name: str, calendar_name, start_time):\n",
    "    \"\"\"\n",
    "    adding reminders to calendar\n",
    "\n",
    "    #TODO define list of forgotten habits\n",
    "    #TODO define time to remind - small timeslots(?)\n",
    "\n",
    "    :param name: title of reminder\n",
    "    :param calendar_name: calendar type name\n",
    "    :param start_time: time of reminder\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    popup = Event(name,\n",
    "                  start=start_time,\n",
    "                  reminders=[\n",
    "                        PopupReminder(minutes_before_start=1)\n",
    "                  ])\n",
    "    calendar_name.add_event(popup)\n",
    "    print('POPUP added' + \" \" + name)\n",
    "\n",
    "# add_popup_reminder('blablalba', main_calendar, D.now()+2*minutes)\n",
    "\n",
    "def delete_calendar_tasks(calendar):\n",
    "    \"\"\"delete all events in calendar\"\"\"\n",
    "\n",
    "    for ev in calendar:\n",
    "        calendar.delete_event(ev)\n",
    "\n",
    "\n",
    "def get_list_tasks_today(calendar):\n",
    "    \"\"\"without repetitions\"\"\"\n",
    "\n",
    "    ll = set([e.summary for e in calendar[D.now():D.now()+ 1* days:'updated']])\n",
    "    return ll\n",
    "\n",
    "\n",
    "\n",
    "def put_tasks1(list_of_tasks_names, df_tasks11, calendar_name):\n",
    "    \"\"\"\n",
    "    Taking list of predicted task names and pulling them to the Gcalendar\n",
    "    checking for 1 day window - if there are tasks?\n",
    "    if there are - getting the free intervals checking their size\n",
    "    if no enough sized timeslots, putting tasks at the end, after last task\n",
    "\n",
    "    :param list_of_tasks_names: list of predicted task names\n",
    "    :param df_tasks11: dataframe to get TTC metric for putting into calendar\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    def how_many_tasks():\n",
    "        return len(find_timeslot_for_task(calendar_name)[1])\n",
    "\n",
    "    for i in set(list_of_tasks_names[:5]): # take first 5 task of sorted tasks\n",
    "        if '----' not in i:\n",
    "            num_tasks = how_many_tasks()\n",
    "            gaps = find_timeslot_for_task(calendar_name)[0]\n",
    "\n",
    "            if num_tasks == 0: # if schedule in 3 day range ( see find_timeslot_for_task() ) is empty\n",
    "                if D.today()[11] > D.now():\n",
    "                    start_task_time = D.today()[11]\n",
    "                else:\n",
    "                    start_task_time = D.now() + 10 * minutes\n",
    "\n",
    "                if df_tasks11[df_tasks11.subject == i].TTC.notna().values.any():   # check if there is TTC metric\n",
    "                    task_duration = int(df_tasks11.loc[df_tasks11.subject==i].TTC.values[0])\n",
    "                else:\n",
    "                    task_duration = 1 # default time period for small not TTC defined task\n",
    "\n",
    "                if task_duration <= 1:  # if work time of task dont need to be sliced\n",
    "                    add_sessions_to_gcal(calendar_name, name=i, start_time=start_task_time,\n",
    "                                         end_time=start_task_time + task_duration * 60 * minutes)\n",
    "                    time.sleep(5)\n",
    "                    continue\n",
    "\n",
    "                elif task_duration > 1:     # if task need to be divided\n",
    "                    number_of_sprints = task_duration.round(0) + 1\n",
    "                    for kk in range(number_of_sprints): # adding task divided in 1-hour sprints\n",
    "                        add_sessions_to_gcal(calendar_name, name=i, start_time=start_task_time,\n",
    "                                             end_time=start_task_time + 70 * kk * minutes)\n",
    "                        time.sleep(5)\n",
    "                        continue\n",
    "\n",
    "            elif num_tasks == 1:  # if schedule is not empty\n",
    "                add_sessions_to_gcal(calendar_name, name=i,\n",
    "                                     start_time=find_timeslot_for_task(calendar_name)[2][0] + 10 * minutes,\n",
    "                                     end_time=find_timeslot_for_task(calendar_name)[2][0] + 70 * minutes)\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "\n",
    "            elif num_tasks > 1:     # if schedule is not empty\n",
    "                if df_tasks11[df_tasks11.subject == i].TTC.notna().values.any():\n",
    "                    task_duration = int(df_tasks11.loc[df_tasks11.subject==i].TTC.values[0])\n",
    "                else:\n",
    "                    task_duration = 1\n",
    "\n",
    "                i_ = 0  # number of times one task added\n",
    "                n_gap = 0  # index of gap\n",
    "\n",
    "                for gap in gaps:   # search for the right gap for task\n",
    "                    if gap.seconds/3600 >= task_duration and i_ < 1:\n",
    "                        print(gap.seconds//3600)\n",
    "                        print(task_duration)\n",
    "\n",
    "                        add_sessions_to_gcal(calendar_name,\n",
    "                                        name=i,\n",
    "                                        start_time=find_timeslot_for_task(calendar_name)[2][n_gap] + 10 * minutes,\n",
    "                                        end_time=find_timeslot_for_task(calendar_name)[2][n_gap] + 70 * minutes)\n",
    "                        time.sleep(2)\n",
    "                        i_ += 1\n",
    "                        n_gap += 1\n",
    "                        continue\n",
    "\n",
    "                    else: # if no right gap add to the end\n",
    "                        print('too small gap OR already added')\n",
    "                        n_gap += 1\n",
    "                        continue\n",
    "\n",
    "                if i_ < 1:  # in case task never added to the gaps add it to the end\n",
    "                    print('adding to the end')\n",
    "\n",
    "                    add_sessions_to_gcal(calendar_name,\n",
    "                                         name=i,\n",
    "                                         start_time=find_timeslot_for_task(calendar_name)[2][-1] + 10 * minutes,\n",
    "                                         end_time=find_timeslot_for_task(calendar_name)[2][-1] + 70 * minutes)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "most_forgotten, most_active = cold_start_ml(df_tasks_3_t)\n",
    "\n",
    "list_of_tasks = cold_start_ml(df_tasks_3_t)[1]\n",
    "sessions_calendar = GoogleCalendar(config.get('GCALENDAR', 'sessions'), credentials_path='credentials.json')\n",
    "\n",
    "delete_calendar_tasks(sessions_calendar)\n",
    "time.sleep(10)\n",
    "\n",
    "\n",
    "# put_tasks1(list_of_tasks_names=most_forgotten, df_tasks11=df_tasks_3_t, calendar_name=sessions_calendar)\n",
    "# time.sleep(20)\n",
    "\n",
    "# put_tasks1(list_of_tasks_names=most_active, df_tasks11=df_tasks_3_t, calendar_name=sessions_calendar)\n",
    "# put_tasks1(list_of_tasks_names=list_of_tasks, df_tasks11=df_tasks_3_t, calendar_name=sessions_calendar)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_tasks_3_t[df_tasks_3_t.subject=='MY CV REVIEW'].TTC.notna().values.any()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "\n",
    "categories = ['Bitterness','Froth','Price',\n",
    "              'Content', 'Mouthfeel']\n",
    "\n",
    "\n",
    "\n",
    "fig12 = px.line_polar(out,\n",
    "                        r=out.act,\n",
    "                        theta=out.life_area,\n",
    "                        line_close=True,  line_shape = 'spline',\n",
    "                        animation_frame = out.datetime_rnd,\n",
    "                        title='Emotions',\n",
    "                        # fill='toself',\n",
    "                        # fillcolor='rgba(0, 255, 0, 0.4)',\n",
    "                        # range_r=(0,2),\n",
    "                        color_discrete_sequence=px.colors.sequential.Plasma_r,\n",
    "                        template=\"plotly_dark\",\n",
    "                 )\n",
    "\n",
    "\n",
    "fig12 = go.Figure()\n",
    "\n",
    "fig12.add_trace(go.Scatterpolar(\n",
    "                        r=out.act,\n",
    "                        theta=out.life_area,\n",
    "                        line_close=dict({True:1}),  line_shape = dict({'spline':1}),\n",
    "                        animation_frame = out.datetime_rnd,\n",
    "                        # title='Emotions',\n",
    "                        # fill='toself',\n",
    "                        # fillcolor='rgba(0, 255, 0, 0.4)',\n",
    "                        # range_r=(0,2),\n",
    "                        color_discrete_sequence=px.colors.sequential.Plasma_r,\n",
    "                        template=dict({\"plotly_dark\":1}),\n",
    "))\n",
    "fig12.add_trace(go.Scatterpolar(\n",
    "      r=[4, 3, 2.5, 1, 2],\n",
    "      theta=categories,\n",
    "      fill='toself',\n",
    "      name='Product B'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "  polar=dict(\n",
    "    radialaxis=dict(\n",
    "      visible=True,\n",
    "      range=[0, 5]\n",
    "    )),\n",
    "  showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#only from sessions df\n",
    "number_tasks_per_day_per_task(df_tasks_3_t).reset_index()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "number_hard_tasks_per_m(df_tasks_3_t).iloc[:,:1].reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TODO WTFFFFF\n",
    "check_goals_difficulty(df_tasks_3_t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tasks_done_per_month(df_tasks_3_t).iloc[:,:1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "amount_complited_tasks_permonth(df_tasks_3_t).iloc[:,:1].reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "amount_complited_tasks_per_list_month(df_tasks_3_t, 'BACKLOG life').iloc[:,:1].reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#creativity as addded tasks to todo lists\n",
    "creat = amount_new_tasks_per_day(df_tasks_3_t)\n",
    "mean_creat = creat.subject.mean()\n",
    "today_creat = creat.subject.iloc[-1]\n",
    "print(mean_creat)\n",
    "print(today_creat)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_tasks_3_t[df_tasks_3_t.underrated==False]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_tasks_3_t[df_tasks_3_t.metricks.notnull()]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_tasks_3_t[(df_tasks_3_t.underrated==False)&(df_tasks_3_t.status=='NotStarted')]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_sessions.groupby(['subject']).agg({'duration':sum})#.reset_index().mean()/3600"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_sessions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TODO Make timeseries for emotion balance.\n",
    "# Associate ((????)) connect it to sessions time\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#trying to visualise\n",
    "#try to astype linux datetime format for x for go.Violin\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.colors import n_colors\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "fig = go.Figure()\n",
    "colors = n_colors('rgb(5, 200, 200)', 'rgb(200, 10, 10)', 30, colortype='rgb')\n",
    "\n",
    "left_range = df_emotions1[\"datetime_rnd\"].max() + relativedelta(months=-1)\n",
    "right_range = df_emotions1[\"datetime_rnd\"].max()\n",
    "\n",
    "for i,color in zip(df_emotions1.iloc[:,2:], colors):\n",
    "    # y=df_emotions1.loc[:,i],\n",
    "    # fig.add_trace(go.Violin(x=df_emotions1[\"datetime_rnd\"][109:].astype(str), y=np.array(df_emotions1.loc[109:,i]),\n",
    "    #                         line_color=color))#, name=i\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=df_emotions1[\"datetime_rnd\"], y=df_emotions1.loc[:,i],\n",
    "                             name=i, mode=\"lines\",\n",
    "                             )) #, line_color=color line_shape ='spline'\n",
    "\n",
    "fig.update_layout(\n",
    "        title=\"Emotions\", xaxis_title=\"Date\", yaxis_title=\"Close\",\n",
    "        template=\"plotly_dark\",yaxis_range=[0,1.5], xaxis_range=[left_range,right_range]\n",
    "    )\n",
    "# fig.update_traces(orientation='h', side='positive', width=2, points=False)\n",
    "# fig.update_layout(xaxis_showgrid=False, xaxis_zeroline=False)\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tttest+1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tttest = df_emotions1.copy().drop(columns = {'datetime_rnd',\n",
    "                   'act'}).iloc[5:37,:].T\n",
    "tttest = np.array(tttest+1)\n",
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.colors import n_colors\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "# 12 sets of normal distributed random data, with increasing mean and standard deviation\n",
    "data = (np.linspace(1, 2, 12)[:, np.newaxis] * np.random.randn(12, 200) +\n",
    "            (np.arange(12) + 2 * np.random.random(12))[:, np.newaxis])\n",
    "colors = n_colors('rgb(5, 200, 200)', 'rgb(200, 10, 10)', 32, colortype='rgb')\n",
    "# print(data[:3])\n",
    "\n",
    "fig = go.Figure()\n",
    "for data_line, color in zip(tttest, colors):\n",
    "    print(data_line)\n",
    "    print(color)\n",
    "    fig.add_trace(go.Violin(x=data_line, line_color=color))\n",
    "\n",
    "fig.update_traces(orientation='h', side='positive', width=3, points=False)\n",
    "fig.update_layout(xaxis_showgrid=False, xaxis_zeroline=False,template=\"plotly_dark\")\n",
    "fig.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.colors import n_colors\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "# 12 sets of normal distributed random data, with increasing mean and standard deviation\n",
    "data = (np.linspace(1, 2, 12)[:, np.newaxis] * np.random.randn(12, 200) +\n",
    "            (np.arange(12) + 2 * np.random.random(12))[:, np.newaxis])\n",
    "colors = n_colors('rgb(5, 200, 200)', 'rgb(200, 10, 10)', 12, colortype='rgb')\n",
    "# print(data[:3])\n",
    "\n",
    "fig = go.Figure()\n",
    "for data_line, color in zip(data, colors):\n",
    "    # print(data_line)\n",
    "    # print(color)\n",
    "    fig.add_trace(go.Violin(x=data_line, line_color=color))\n",
    "\n",
    "fig.update_traces(orientation='h', side='positive', width=3, points=False)\n",
    "fig.update_layout(xaxis_showgrid=False, xaxis_zeroline=False,template=\"plotly_dark\")\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(data)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(np.linspace(1, 2, 12)[:, np.newaxis] * np.random.randn(12, 200) +\n",
    "            (np.arange(12) + 2 * np.random.random(12))[:, np.newaxis])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# inspiration https://medium.com/@marcosanchezayala/plotting-pokemon-attributes-plotly-polar-plots-and-animations-319934b60f0e\n",
    "#https://stackoverflow.com/questions/71781424/i-want-to-make-an-animated-polar-chart-but-the-chart-i-get-only-has-one-radii-wi\n",
    "\n",
    "\n",
    "\n",
    "# preparing DFs\n",
    "df_emotions2 = df_emotions1.drop(columns=['act'])\n",
    "# df_emotions2\n",
    "df_emotions2 = pd.melt(df_emotions2, id_vars='datetime_rnd', var_name='attribute', value_name='attribute_value')\n",
    "df_emotions2['datetime_rnd'] = df_emotions2['datetime_rnd'].astype(str)\n",
    "df_emotions2['attribute_value']=df_emotions2['attribute_value']+0.5\n",
    "\n",
    "import plotly.express as px\n",
    "# import plotly.offline as pyo\n",
    "\n",
    "fig = px.line_polar(df_emotions2,\n",
    "                    r='attribute_value',\n",
    "                    theta='attribute',\n",
    "                    line_close=True,  line_shape = 'spline',\n",
    "                    animation_frame = 'datetime_rnd',\n",
    "                    title='Emotions',\n",
    "                    range_r=(0,2),\n",
    "                    color_discrete_sequence=px.colors.sequential.Plasma_r,\n",
    "                    template=\"plotly_dark\",\n",
    "             )\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    height=600,\n",
    "    width=800,\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "# pyo.plot(fig)\n",
    "fig.write_html('plot_emotions.html')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#PLOTTING ANIMATED TIMESERIES FOR habitts ARCHIVE\n",
    "\n",
    "# inspiration https://medium.com/@marcosanchezayala/plotting-pokemon-attributes-plotly-polar-plots-and-animations-319934b60f0e\n",
    "#https://stackoverflow.com/questions/71781424/i-want-to-make-an-animated-polar-chart-but-the-chart-i-get-only-has-one-radii-wi\n",
    "\n",
    "\n",
    "\n",
    "#one-hot encoding for trying get data for plotting timeseries on radial plot\n",
    "#getting dummies from list from grouped by rounded 10m datetime periods\n",
    "#https://stackoverflow.com/questions/29034928/pandas-convert-a-column-of-list-to-dummies\n",
    "\n",
    "df_habits1 = df_habits.groupby('datetime_rnd')['act'].agg(list).reset_index()#.iloc[1,:]\n",
    "\n",
    "# GENERATION getdummies from list of emotions (act column) grouped by 10min periods\n",
    "df_habits1 = df_habits1.join(df_habits1['act'].str.join('|').str.get_dummies())\n",
    "# df_habits1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# preparing DFs\n",
    "df_habits2 = df_habits1.drop(columns=['act'])\n",
    "# df_emotions2\n",
    "df_habits2 = pd.melt(df_habits2, id_vars='datetime_rnd', var_name='attribute', value_name='attribute_value')\n",
    "df_habits2['datetime_rnd'] = df_habits2['datetime_rnd'].astype(str)\n",
    "#adding 1 just for looking better\n",
    "df_habits2['attribute_value']=df_habits2['attribute_value']+0.5\n",
    "\n",
    "import plotly.express as px\n",
    "# import plotly.offline as pyo\n",
    "\n",
    "fig = px.line_polar(df_habits2,\n",
    "                    r='attribute_value',\n",
    "                    theta='attribute',\n",
    "                    line_close=True,  line_shape = 'spline',\n",
    "                    animation_frame = 'datetime_rnd',\n",
    "                    title='Habits',\n",
    "                    range_r=(0,2),\n",
    "                    color_discrete_sequence=px.colors.sequential.Plasma_r,\n",
    "                    template=\"plotly_dark\",\n",
    "             )\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    height=600,\n",
    "    width=800,\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "# pyo.plot(fig)\n",
    "fig.write_html('plot_habitts.html')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#feature hashing instead of onehot encoding\n",
    "#only for ML stage, cous of not interprateble\n",
    "# https://www.kaggle.com/code/dansbecker/using-categorical-data-with-one-hot-encoding/notebook\n",
    "# https://scikit-learn.org/stable/modules/feature_extraction.html#feature-hashing\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "# n_features contains the number of bits you want in your hash value.\n",
    "h = FeatureHasher(n_features = 15, input_type ='string')\n",
    "\n",
    "# transforming the column after fitting\n",
    "hashed_Feature = h.fit_transform(df_emotions['act'])\n",
    "\n",
    "hashed_Feature = hashed_Feature.toarray()\n",
    "pd.DataFrame(hashed_Feature)\n",
    "# df___ = pd.concat([df_emotions, pd.DataFrame(hashed_Feature)], axis = 1)\n",
    "# df___.head(10)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/4-categorical-encoding-concepts-to-know-for-data-scientists-e144851c6383\n",
    "#\n",
    "# import category_encoders as ce\n",
    "# encoder=ce.HashingEncoder(cols='model_year',n_components=5)\n",
    "# hash_res = encoder.fit_transform(mpg['model_year'])\n",
    "# hash_res.sample(5)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#auto feature engeneering\n",
    "#https://towardsdatascience.com/easy-automated-feature-engineering-for-machine-learning-model-ea00c5059dd6\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df_sessions.groupby(['description']).head(111)\n",
    "#\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df_sessions['description'].iloc[1:]\n",
    "#"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df_sessions_tasks_duration.reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# list_of_cumsum_sessions = df_sessions_tasks_duration.reset_index().subject.tolist()\n",
    "#\n",
    "# df_tasks_3['duration'] = df_sessions_tasks_duration.reset_index() for session_name in list_of_cumsum_sessions\n",
    "# df_tasks_3.join(df_sessions_tasks_duration, on='subject', how='left')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pd.merge(df_tasks_3 , df_sessions_tasks_duration.reset_index() , on=['subject'])\n",
    "#\n",
    "#\n",
    "#"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# list_of_cumsum_sessions = df_sessions_tasks_duration.reset_index().subject.tolist()\n",
    "# # df_tasks_3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df_sessions_tasks_duration.reset_index()['subject']=='ORCHESTRATION 10 3 4 3 3'\n",
    "#"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pd.merge(df_tasks_3, df_sessions_tasks_duration.reset_index(),left_on='subject',right_on='subject', how='left')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# df_sessions_tasks_duration = df_sessions.groupby(['subject'])['duration'].sum()\n",
    "#\n",
    "# test = pd.merge(df_tasks_3, df_sessions_tasks_duration.reset_index(),left_on='subject',right_on='subject', how='left')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test['underrated'] = (test['duration'].astype('Int32') / 3600 - test['TTC'].astype('Int32')) > (0.15 *\n",
    "#                                                                                                  test['TTC'].astype(\n",
    "#                                                                                                      'Int32')+0.01)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test[test['underrated']==True]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test[test['metricks'].astype('Int32')!=0]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test.info()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df_tasks_3\n",
    "# TTC\tPRI\tDIFF PLEAS RESIS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#one-hot encoding for trying get data for plotting timeseries on radial plot\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# enc = OneHotEncoder()\n",
    "# # transforming the column after fitting\n",
    "# enc = enc.fit_transform(df_emotions[['act']]).toarray()\n",
    "# # converting arrays to a dataframe\n",
    "# encoded_colm = pd.DataFrame(enc)\n",
    "# # concatenating dataframes\n",
    "#\n",
    "# # encoded_colm faster\n",
    "# df_emotions1 = pd.concat([df_emotions, encoded_colm], axis=1)\n",
    "# df_emotions1\n",
    "# # # removing the encoded column.\n",
    "# # df = df.drop(['nom_0'], axis=1)\n",
    "# # df.head(10)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df = px.data.wind()\n",
    "fig = px.line_polar(df, r=\"frequency\", theta=\"direction\", color=\"strength\", line_close=True,\n",
    "                    color_discrete_sequence=px.colors.sequential.Plasma_r,\n",
    "                    template=\"plotly_dark\",)\n",
    "fig.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df = px.data.gapminder()\n",
    "fig = px.scatter(df, x=\"gdpPercap\", y=\"lifeExp\", animation_frame=\"year\", animation_group=\"country\",\n",
    "           size=\"pop\", color=\"continent\", hover_name=\"country\",\n",
    "           log_x=True, size_max=55, range_x=[100,100000], range_y=[25,90])\n",
    "\n",
    "# fig[\"layout\"].pop(\"updatemenus\") # optional, drop animation buttons\n",
    "fig.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "\n",
    "\n",
    "categories = ['Food Quality', 'Food Variety', 'Service Quality', 'Ambience', 'Affordability']\n",
    "categories = [*categories, categories[0]]\n",
    "\n",
    "restaurant_1 = [4, 4, 5, 4, 3]\n",
    "restaurant_2 = [5, 5, 4, 5, 2]\n",
    "restaurant_3 = [3, 4, 5, 3, 5]\n",
    "restaurant_1 = [*restaurant_1, restaurant_1[0]]\n",
    "restaurant_2 = [*restaurant_2, restaurant_2[0]]\n",
    "restaurant_3 = [*restaurant_3, restaurant_3[0]]\n",
    "\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatterpolar(r=restaurant_1, theta=categories, name='Restaurant 1'),\n",
    "        go.Scatterpolar(r=restaurant_2, theta=categories, name='Restaurant 2'),\n",
    "        go.Scatterpolar(r=restaurant_3, theta=categories, name='Restaurant 3')\n",
    "    ],\n",
    "    layout=go.Layout(\n",
    "        title=go.layout.Title(text='Restaurant comparison'),\n",
    "        polar={'radialaxis': {'visible': True}},\n",
    "        showlegend=True\n",
    "    )\n",
    ")\n",
    "\n",
    "pyo.plot(fig)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "restaurant_1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df_tasks_3['PLEASURE_aft'] = None\n",
    "# for i in df_tasks_3[df_tasks_3.status=='Completed'].subject:\n",
    "\n",
    "\n",
    "# count_emotion_balance_of_task_completion_day_by_task_name('REFACTORING 4 3 2 2 3')\n",
    "#\n",
    "#\n",
    "# dateee=date_of_task_completion('guberman goal setting video').iloc[0]\n",
    "#\n",
    "# df_emotions1[df_emotions1['datetime_rnd'].dt.strftime(\"%Y-%m-%d\")==dateee].act.sum()\n",
    "#\n",
    "# indd = df_tasks_3[df_tasks_3.subject=='REFACTORING 4 3 2 2 3'].index\n",
    "#\n",
    "# df_tasks_3.iloc[indd,:].PLEASURE_aft\n",
    "\n",
    "# date_of_task_completion('test forked running bot')#.astype('datetime64')\n",
    "# df_emotions1[df_emotions1['datetime_rnd'].iloc[1].strftime(\"%Y-%m-%d\")==date_of_task_completion('test forked running bot').iloc[0]]\n",
    "#\n",
    "# df_tasks_3[df_tasks_3.status=='Completed']\n",
    "# df_emotions1.datetime_rnd.iloc[1].strftime(\"%Y-%m-%d\")\n",
    "# date_of_task_completion('test forked running bot').iloc[0]\n",
    "# df_emotions1['datetime_rnd'].astype(str)#.iloc[1].strftime(\"%Y-%m-%d\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def first_session_date_by_taskname(taskname):\n",
    "#     \"\"\"return date of first session of task\"\"\"\n",
    "#     if len(df_sessions[df_sessions.subject==taskname].start.agg(list))==0:\n",
    "#         return None\n",
    "#     else:\n",
    "#         return min(df_sessions[df_sessions.subject==taskname].start.agg(list))\n",
    "#\n",
    "# # first_session_date_by_taskname('calendar sync visualisation 4 2 3 4 1')\n",
    "# # df_sessions[df_sessions.subject=='calendar sync visualisation 4 2 3 4 1'].head()\n",
    "#\n",
    "# # load_emotions_habits_values()\n",
    "#\n",
    "# def date_of_task_completion(taskname):\n",
    "#     \"\"\"take date of completed task\"\"\"\n",
    "#     mask__ = (df_tasks_3.subject==taskname)\n",
    "#     #&(isinstance(df_tasks_3[df_tasks_3.subject==taskname].completed_datetime,datetime.datetime))\n",
    "#     return df_tasks_3[mask__].completed_datetime\n",
    "#\n",
    "# # date_of_task_completion('test forked running bot').astype('datetime64') #check\n",
    "#\n",
    "#\n",
    "# def common_list_items(a,b):\n",
    "#     from collections import Counter\n",
    "#     ca = Counter(a)\n",
    "#     cb = Counter(b)\n",
    "#\n",
    "#     result = [a for b in ([key] * min(ca[key], cb[key])\n",
    "#                           for key in ca\n",
    "#                           if key in cb) for a in b]\n",
    "#     return result\n",
    "#\n",
    "#\n",
    "# #TODO create mean of emotion balance during ALL task sessions\n",
    "# def count_emotion_balance_of_task_completion_day_by_task_name(taskname, regime=0, values_list=[]):\n",
    "#     \"\"\"get list of emotions during !!!! COMPLETION_day!!!!! by taskname\"\"\"\n",
    "#\n",
    "#     global emotions_values, habits_values, emotions_and_habits_values\n",
    "#\n",
    "#\n",
    "#\n",
    "#     dateee=date_of_task_completion(taskname).iloc[0]\n",
    "#     # print(dateee)\n",
    "#     # print(df_emotions1['datetime_rnd'].dt.strftime(\"%Y-%m-%d\"))\n",
    "#     mask___ = (df_emotions1['datetime_rnd'].dt.strftime(\"%Y-%m-%d\")==dateee)\n",
    "#     # print(mask___)\n",
    "#     daily_list_of_emotions = df_emotions1[mask___].act.sum()\n",
    "#     # print(dayly_list_of_emotions)\n",
    "#     daily_emotional_balance = 0\n",
    "#\n",
    "#     #not all tasks are completed after i started tracking emotions,\n",
    "#     # so check if 0 registered emotions\n",
    "#     if daily_list_of_emotions!=0 and regime==0:\n",
    "#         for ik in emotions_values.keys():\n",
    "#             if ik in daily_list_of_emotions:\n",
    "#                 daily_emotional_balance += emotions_values[ik]\n",
    "#             return daily_emotional_balance\n",
    "#     #part for counting frustration and procrastination\n",
    "#     else:\n",
    "#         if daily_list_of_emotions!=0 and regime==1:\n",
    "#             for ik in common_list_items(emotions_and_habits_values.keys(),values_list):\n",
    "#                 if ik in daily_list_of_emotions:\n",
    "#                     daily_emotional_balance += emotions_and_habits_values[ik]\n",
    "#             return daily_emotional_balance\n",
    "#     # print(daily_emotional_balance)\n",
    "#\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #ADDING MORE FEATURES for assuming metrics of tasks, based on secondary features\n",
    "#\n",
    "# # TTC_aft - sessions datetime sum if task done\n",
    "# df_tasks_3_t = after_metric_ttc(df=df_sessions, df1=df_tasks_3)\n",
    "# # df_tasks_3_t[df_tasks_3_t.metricks.notnull()] #checking\n",
    "#\n",
    "# df_tasks_3_t['completed_datetime'] = df_tasks_3_t['completed_datetime'].astype('datetime64')\n",
    "# df_tasks_3_t['created_datetime'] = df_tasks_3_t['created_datetime'].astype('datetime64')\n",
    "#\n",
    "# # PRI_aft - compared date started(first session in toggl)-created /time done for each task compare\n",
    "#\n",
    "# #TODO check ! why there is so small amount of counted cells\n",
    "# for i in df_tasks_3_t[df_tasks_3_t.status=='Completed'].subject:\n",
    "#     if isinstance(first_session_date_by_taskname(i),datetime.datetime):\n",
    "#         mask_ = (df_tasks_3_t.subject==i)\n",
    "#         df_tasks_3_t['PRI_aft'] = (df_tasks_3_t[mask_].completed_datetime -\n",
    "#                                                      first_session_date_by_taskname(i).replace(tzinfo=None) )/(df_tasks_3_t[mask_].created_datetime - first_session_date_by_taskname(i).replace(tzinfo=None))\n",
    "#\n",
    "#\n",
    "#\n",
    "# # PLEASURE_aft - end day emotional balance\n",
    "# #TODO, or mean of all days when were sessions of that task)\n",
    "# # FOR that ONE  is NEEDED df_emotions1 and df_tasks_3 DFs\n",
    "# # end day emotional balance (TODO, or mean of all days when were sessions of that task)\n",
    "\n",
    "#\n",
    "# #emotion balance by date of completed task\n",
    "# for k in df_tasks_3_t[df_tasks_3_t.status=='Completed'].subject:\n",
    "#     # print(k)\n",
    "#     indd = df_tasks_3_t[df_tasks_3_t.subject==k].index\n",
    "#     df_tasks_3_t.loc[indd, 'PLEASURE_aft'] = count_emotion_balance_of_task_completion_day_by_task_name(k, None)\n",
    "#\n",
    "#\n",
    "# # df_tasks_3_t[df_tasks_3_t.status=='Completed'] #cheking\n",
    "#\n",
    "#\n",
    "# # DIFCLT_aft -  select frustration type of emotions, return were they there,\n",
    "# #                   input list of sessions dates of certain\n",
    "# #                   list of emotions pleasuring or stress  for certain task done\n",
    "# # RES_aft amount of procrastination, too much youtube, or mobile screentime(????)\n",
    "#\n",
    "#\n",
    "#\n",
    "# # make lists for frustration and procrastination\n",
    "# frustration = ['burnouted', 'emotionally UNbalanced', 'anxiety', 'confusion', '-fear', 'sadness', '-surprise',\n",
    "#                    'dissatisfaction']\n",
    "# procrastination = ['burnouted', 'procrastinated', 'boredom', 'horror', 'jrk', 'porn', 'too much movies',\n",
    "#                        'too much youtube', 'too much social media', 'too much news']\n",
    "\n",
    "# #TODO, when data on completed tasks will be more, what happening with that columns\n",
    "# #count daily amount of such emotions\n",
    "# for k in df_tasks_3_t[df_tasks_3_t.status=='Completed'].subject:\n",
    "#     # print(k)\n",
    "#     indd = df_tasks_3_t[df_tasks_3_t.subject==k].index\n",
    "#     df_tasks_3_t.loc[indd, 'DIFCLT_aft'] = count_emotion_balance_of_task_completion_day_by_task_name(k, regime=1,\n",
    "#                                                                                                      values_list=frustration)\n",
    "#     df_tasks_3_t.loc[indd, 'RES_aft'] = count_emotion_balance_of_task_completion_day_by_task_name(k, regime=1,\n",
    "#                                                                                                      values_list= procrastination)\n",
    "#\n",
    "# # df_tasks_3_t[df_tasks_3_t.DIFCLT_aft.notna()] #check\n",
    "#\n",
    "#\n",
    "#\n",
    "# #underrated as for TTC metric\n",
    "# check_error_rate_predicting_ttc(df1=df_tasks_3_t)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TESTING PD.MELT fUNCTION\n",
    "# \"D:\\downloads\\artists.csv\"\n",
    "# \"D:\\downloads\\tracks.csv\"\n",
    "# artists = pd.read_csv(r\"D:\\downloads\\artists.csv\")\n",
    "spotify_data = pd.read_csv(r\"D:\\downloads\\tracks.csv\").head(10000)\n",
    "spotify_data.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "med_spotify = spotify_data.drop(columns=['name', 'explicit', 'artists', 'key', 'mode', 'time_signature', 'tempo', 'duration_ms', 'loudness'])\n",
    "\n",
    "\n",
    "med_spotify"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "med_spotify = med_spotify.groupby('release_date').median()\n",
    "# med_spotify.reset_index(inplace=True)\n",
    "med_spotify"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "med_spotify.reset_index(inplace=True)\n",
    "med_spotify"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tetete = pd.melt(med_spotify, id_vars='release_date', var_name='attribute', value_name='attribute_value')\n",
    "tetete.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "med_spotify = spotify_data.drop(columns=['name', 'explicit', 'artists', 'key', 'mode', 'time_signature', 'tempo', 'duration_ms', 'loudness'])\n",
    "med_spotify = med_spotify.groupby('release_date').median()\n",
    "med_spotify.reset_index(inplace=True)\n",
    "plot_data = pd.melt(med_spotify, id_vars='release_date', var_name='attribute', value_name='attribute_value')\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.line_polar(plot_data,\n",
    "                    r='attribute_value',\n",
    "                    theta='attribute',\n",
    "                    line_close=True,\n",
    "                    animation_frame = 'release_date',\n",
    "                    title='Spotify',\n",
    "                    template = 'ggplot2'\n",
    "             )\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    height=600,\n",
    "    width=800,\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plotting of 1strow - period in df\n",
    "#take only first row and make it 'vertical'\n",
    "test_graph = df_emotions1.iloc[0,:].reset_index().iloc[2:,:]\n",
    "# test_graph\n",
    "\n",
    "# inspiration https://medium.com/@marcosanchezayala/plotting-pokemon-attributes-plotly-polar-plots-and-animations-319934b60f0e\n",
    "#https://stackoverflow.com/questions/71781424/i-want-to-make-an-animated-polar-chart-but-the-chart-i-get-only-has-one-radii-wi\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.line_polar(test_graph, r=0, theta=\"index\",# color=\"strength\", animation_frame=\"year\",\n",
    "                    line_shape = 'spline', line_close=True,range_r=(0,2),\n",
    "                    color_discrete_sequence=px.colors.sequential.Plasma_r,\n",
    "                    template=\"plotly_dark\",)\n",
    "fig.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# from prefect import task, flow\n",
    "# from UI_orchestration import *\n",
    "\n",
    "\n",
    "# import streamlit.cli as cli\n",
    "#\n",
    "# import sys\n",
    "#\n",
    "#\n",
    "# sys.argv = ['0','run','myApp']\n",
    "# name = \"main\"\n",
    "#\n",
    "# cli.main()\n",
    "\n",
    "\n",
    "# import sys\n",
    "# from streamlit import cli as stcli\n",
    "#\n",
    "# if __name__ == '__main__':\n",
    "#     sys.argv = [\"streamlit\", \"run\", \"APP_NAME.py\"]\n",
    "#     sys.exit(stcli.main())\n",
    "\n",
    "#\n",
    "# import sys\n",
    "#\n",
    "# # total arguments\n",
    "# n = len(sys.argv)\n",
    "# print(\"Total arguments passed:\", n)\n",
    "#\n",
    "# # Arguments passed\n",
    "# print(\"\\nName of Python script:\", sys.argv[0])\n",
    "#\n",
    "# print(\"\\nArguments passed:\", end=\" \")\n",
    "# for i in range(1, n):\n",
    "#     print(sys.argv[i], end=\" \")\n",
    "#\n",
    "# # Addition of numbers\n",
    "# Sum = 0\n",
    "# # Using argparse module\n",
    "# for i in range(1, n):\n",
    "#     Sum += int(sys.argv[i])\n",
    "#\n",
    "# print(\"\\n\\nResult:\", Sum)\n",
    "#\n",
    "# # Python program to demonstrate\n",
    "# # command line arguments\n",
    "\n",
    "#\n",
    "# import getopt, sys\n",
    "#\n",
    "# # Remove 1st argument from the\n",
    "# # list of command line arguments\n",
    "# argumentList = sys.argv[1:]\n",
    "#\n",
    "# # Options\n",
    "# options = \"cl:\"\n",
    "#\n",
    "# # Long options\n",
    "# long_options = [\"cloud\", \"local\", \"Output=\"]\n",
    "#\n",
    "# try:\n",
    "#     # Parsing argument\n",
    "#     arguments, values = getopt.getopt(argumentList, options, long_options)\n",
    "#\n",
    "#     # checking each argument\n",
    "#     for currentArgument, currentValue in arguments:\n",
    "#\n",
    "#         if currentArgument in (\"-l\", \"--local\"):\n",
    "#             print(\"Running Streamlit dashboard locally\"\n",
    "#                   \"visit   -    localhost:\")\n",
    "#\n",
    "#         elif currentArgument in (\"-c\", \"--cloud\"):\n",
    "#             print(\"Running backend in cloud\")\n",
    "#             print(\"\")\n",
    "#\n",
    "#         elif currentArgument in (\"-h\", \"--help\"):\n",
    "#             print((\"for help and documentation visit \"\n",
    "#                    \"link\"\n",
    "#                    \"link\"\n",
    "#                    \"link\")\n",
    "#\n",
    "# except getopt.error as err:\n",
    "#     # output error, and return with an error code\n",
    "#     print(str(err))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

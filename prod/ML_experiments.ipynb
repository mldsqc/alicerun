{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data_preparing import *\n",
    "from bot_answers_analysis import load_emotions_habits_values\n",
    "\n",
    "from data_preparing import memory_usage\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DB_ADASH1, DB_TODO, DB_ACTWATCH, DB_GADGETBRIDGE, DB_ADASH2, DB_ADASH3, DB_ADASH4, DB_EMOTIONS_TEST = read_db_paths()\n",
    "\n",
    "\n",
    "df_sessions = pd.DataFrame(sessions_download())\n",
    "df_sessions.rename(columns={'description': 'subject'}, inplace=True)\n",
    "df_tasks, df_joined = df_tasks_prepare(DB_TODO)\n",
    "df_tasks_2 = tasks_read_metrics(df_tasks, df_joined)\n",
    "df_tasks_3 = tasks_motivation(df_tasks_2)\n",
    "\n",
    "df_emotions, df_habits, df_emotions1 = emotions_habits_df_prepare()\n",
    "\n",
    "df_tasks_3_t = after_features_assumpted(df=df_sessions, df1=df_tasks_3, df_tasks_3=df_tasks_3,\n",
    "                                        df_emotions1=df_emotions1)\n",
    "\n",
    "# TTC_aft - sessions datetime sum if task done - taken from df_sessions - datetime type\n",
    "# PRI_aft - compared date started(first session in toggl)-created /time done for each task compare - relational type\n",
    "# PLEASURE_aft - end day emotional balance at the day task completed (!) - from emotional DF\n",
    "# DIFCLT_aft -  select frustration type of emotions, return were they there,\n",
    "\n",
    "#input list of sessions dates of certain list of emotions pleasuring or stress  for certain task done\n",
    "\n",
    "# RES_aft amount of procrastination type emotions - habits, too much youtube, or mobile screentime(????)\n",
    "#underrated as for TTC metric - did i undervalued TTC metric from\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prepare_df_for_ml(df_tasks_3_t):\n",
    "\n",
    "    df_tasks_4_ml = df_tasks_3_t.copy()\n",
    "\n",
    "\n",
    "    #dealing with not modified tasks modified column\n",
    "    df_tasks_4_ml.body_last_modified=df_tasks_4_ml.body_last_modified.fillna(df_tasks_4_ml.created_datetime)\n",
    "\n",
    "    df_tasks_4_ml['created_datetime_numday'] = df_tasks_4_ml.created_datetime.dt.day_of_week\n",
    "    df_tasks_4_ml['completed_datetime_numday'] = df_tasks_4_ml.completed_datetime.dt.day_of_week\n",
    "    df_tasks_4_ml['body_last_modified_numday'] = df_tasks_4_ml.body_last_modified.astype('datetime64').dt.day_of_week\n",
    "    df_tasks_4_ml['completed_minus_created_dayscount'] = (df_tasks_4_ml.completed_datetime - df_tasks_4_ml\n",
    "                                                          .created_datetime).dt.days+1\n",
    "    df_tasks_4_ml['modified_minus_created_dayscount'] = (df_tasks_4_ml.body_last_modified.astype('datetime64') - df_tasks_4_ml.created_datetime).dt.days\n",
    "\n",
    "\n",
    "    df_tasks_4_ml['status'] = df_tasks_4_ml['status'].astype('category')\n",
    "    df_tasks_4_ml['importance'] = df_tasks_4_ml['importance'].astype('category')\n",
    "    df_tasks_4_ml['group'] = df_tasks_4_ml['group'].astype('category')\n",
    "    df_tasks_4_ml['life_area'] = df_tasks_4_ml['life_area'].astype('category')\n",
    "\n",
    "    df_tasks_4_ml['body_last_modified'] = df_tasks_4_ml['body_last_modified'].astype('datetime64')\n",
    "\n",
    "    df_tasks_4_ml['TTC'] = df_tasks_4_ml['TTC'].astype('Int32')\n",
    "    df_tasks_4_ml['PRI'] = df_tasks_4_ml['PRI'].astype('Int32')\n",
    "    df_tasks_4_ml['DIFF'] = df_tasks_4_ml['DIFF'].astype('Int32')\n",
    "    df_tasks_4_ml['PLEAS'] = df_tasks_4_ml['PLEAS'].astype('Int32')\n",
    "    df_tasks_4_ml['RESIS'] = df_tasks_4_ml['RESIS'].astype('Int32')\n",
    "    df_tasks_4_ml['motivation'] = df_tasks_4_ml['motivation'].astype('Float32')\n",
    "\n",
    "    df_tasks_4_ml['duration'] = df_tasks_4_ml['duration']/3600\n",
    "\n",
    "    #datetime - modify to the day number,\n",
    "    # last modified and completed difference in days\n",
    "    # created and completed difference in days\n",
    "\n",
    "    #\n",
    "    # # body_last_modified\n",
    "    # # created_datetime\n",
    "    # # completed_datetime\n",
    "    # df_tasks_4_ml['created_datetime_numday'] = df_tasks_4_ml.created_datetime.dt.day_of_week\n",
    "    # df_tasks_4_ml['completed_datetime_numday'] = df_tasks_4_ml.completed_datetime.dt.day_of_week\n",
    "    # df_tasks_4_ml['body_last_modified_numday'] = df_tasks_4_ml.body_last_modified.astype('datetime64').dt.day_of_week\n",
    "    # df_tasks_4_ml['completed_minus_created_dayscount'] = (df_tasks_4_ml.completed_datetime - df_tasks_4_ml\n",
    "    #                                                       .created_datetime).dt.days+1\n",
    "    # df_tasks_4_ml['modified_minus_created_dayscount'] = (df_tasks_4_ml.body_last_modified.astype('datetime64') - df_tasks_4_ml.created_datetime).dt.days\n",
    "    #\n",
    "\n",
    "\n",
    "    #get all categorical columns\n",
    "    cat_columns = df_tasks_4_ml.select_dtypes(['category']).columns\n",
    "\n",
    "    #convert all categorical columns to numeric\n",
    "    df_tasks_4_ml[cat_columns] = df_tasks_4_ml[cat_columns].apply(lambda x: pd.factorize(x)[0])\n",
    "\n",
    "    #FILTERING OUT ROWS ON WITCH IMPOSSIBLE TO TRAIN\n",
    "    df_done_tasks_4_ml = df_tasks_4_ml[(df_tasks_4_ml.status == 1)&(df_tasks_4_ml.TTC.notna())]\n",
    "\n",
    "    #SEE HOW MANY DATA WE HAVE TO TRAIN ON\n",
    "    # print(df_done_tasks_4_ml[df_done_tasks_4_ml.completed_datetime >\n",
    "    #                datetime.datetime.strptime('2022-07-05', '%Y-%m-%d')])\n",
    "\n",
    "    # not much values defined by filtering. emotions-df starts from august,\n",
    "    # sessions and tasks DFs differs\n",
    "    #2022-07-05 - more tasks , 2022-08-05 - start time tracking emotions\n",
    "\n",
    "    df_done_tasks_5_ml = df_done_tasks_4_ml[df_done_tasks_4_ml.completed_datetime > datetime.datetime.strptime\n",
    "    ('2022-07-05', '%Y-%m-%d')].copy()\n",
    "\n",
    "    df_done_tasks_5_ml.drop(columns=['body_last_modified', 'created_datetime', 'completed_datetime', 'subject', 'metricks',\n",
    "                                'task_folder_local_id','original_body_content','duration'], inplace=True, axis=1)\n",
    "\n",
    "    # df_done_tasks_5_ml\n",
    "    #,'motivation','duration','TTC_aft','PRI_aft','PLEASURE_aft','DIFCLT_aft', 'RES_aft'\n",
    "\n",
    "    #CONVERTING_TYPES_FOR_CLASSIFICATION\n",
    "    df_done_tasks_5_ml.TTC_aft.fillna(value=df_done_tasks_5_ml.TTC_aft.mean(), inplace=True)\n",
    "    df_done_tasks_5_ml.TTC_aft=df_done_tasks_5_ml.TTC_aft.round(0).astype(int)\n",
    "    df_done_tasks_5_ml.completed_datetime_numday=df_done_tasks_5_ml.completed_datetime_numday.round(0).astype(int)\n",
    "    df_done_tasks_5_ml.completed_minus_created_dayscount=df_done_tasks_5_ml.completed_minus_created_dayscount.round(0).astype(int)\n",
    "    df_done_tasks_5_ml.body_last_modified_numday=df_done_tasks_5_ml.body_last_modified_numday.round(0).astype(int)\n",
    "    df_done_tasks_5_ml.modified_minus_created_dayscount=df_done_tasks_5_ml.modified_minus_created_dayscount.round(0).astype(int)\n",
    "    df_done_tasks_5_ml.underrated=df_done_tasks_5_ml.underrated.astype(int)\n",
    "\n",
    "    return df_done_tasks_5_ml, df_tasks_4_ml\n",
    "\n",
    "df_done_tasks_5_ml = prepare_df_for_ml(df_tasks_3_t)[0]\n",
    "df_tasks_4_ml = prepare_df_for_ml(df_tasks_3_t)[1]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_done_tasks_5_ml"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "col_to_use_to_predict = ['importance', 'group', 'life_area', 'TTC', 'PRI', 'PLEAS', 'DIFF', 'RESIS',\n",
    "    'created_datetime_numday'] #, 'body_last_modified_numday', 'modified_minus_created_dayscount'\n",
    "\n",
    "col_to_predict = ['motivation', 'TTC_aft', 'PRI_aft', 'PLEASURE_aft', 'DIFCLT_aft', 'RES_aft',\n",
    "                      'underrated', 'completed_datetime_numday','completed_minus_created_dayscount']\n",
    "\n",
    "    # scaler = MinMaxScaler()\n",
    "    # df_done_tasks_5_ml[['PRI', 'DIFF','PLEAS','RESIS']] = scaler.fit_transform(df_done_tasks_5_ml[['PRI', 'DIFF','PLEAS',\n",
    "    # 'RESIS']])\n",
    "\n",
    "    # TTC_aft underrated completed_datetime_numday\n",
    "\n",
    "X,y = df_done_tasks_5_ml.loc[:, col_to_use_to_predict], df_done_tasks_5_ml.loc[:,'TTC_aft']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state = 2022)\n",
    "\n",
    "\n",
    "def knn_clf(X_train, X_test, y_train, y_test, detect_best_k=1, plotting=0):\n",
    "    \"\"\"\n",
    "        classification with KNN\n",
    "        for each metric define better K\n",
    "        plotting\n",
    "        saving model in file\n",
    "\n",
    "    \"\"\"\n",
    "    #detect_best_k for KNN\n",
    "    if detect_best_k==1:\n",
    "        # Model complexity\n",
    "        neig = np.arange(1, 10)\n",
    "        train_accuracy = []\n",
    "        test_accuracy = []\n",
    "\n",
    "        # Loop over different values of k\n",
    "        for i, k in enumerate(neig):\n",
    "            # k from 1 to 10(exclude)\n",
    "            knn = KNeighborsClassifier(n_neighbors=k)\n",
    "            # Fit with knn\n",
    "            knn.fit(X_train,y_train)\n",
    "            #train accuracy\n",
    "            train_accuracy.append(knn.score(X_train, y_train))\n",
    "            # test accuracy\n",
    "            test_accuracy.append(knn.score(X_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "        # Plot\n",
    "        if plotting==1:\n",
    "            plt.figure(figsize=[13,8])\n",
    "            plt.plot(neig, test_accuracy, label = 'Testing Accuracy')\n",
    "            plt.plot(neig, train_accuracy, label = 'Training Accuracy')\n",
    "            plt.legend()\n",
    "            plt.title('-value VS Accuracy')\n",
    "            plt.xlabel('Number of Neighbors')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.xticks(neig)\n",
    "            # plt.savefig('graph.png')\n",
    "            plt.show()\n",
    "            print(f\"Best accuracy is {np.max(test_accuracy)} with K = {1+test_accuracy.index(np.max(test_accuracy))}\")\n",
    "\n",
    "        best_k = 1+test_accuracy.index(np.max(test_accuracy))\n",
    "        best_accuracy = np.max(test_accuracy)\n",
    "\n",
    "    return best_k, best_accuracy\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test,\n",
    "\n",
    "def save_load_predict_model_knn(bestk, bestaccuracy, target='TTC_aft',  df_to_predict=X_test,\n",
    "                                train_model=1, save_model_file=1, load_model_and_predict=1):\n",
    "    filename = target + '_' + str(best_k) + '_' + str(bestaccuracy) + '.pkl'\n",
    "\n",
    "    if train_model==1:\n",
    "        knn_best = KNeighborsClassifier(n_neighbors=bestk)\n",
    "\n",
    "        knn_best.fit(X_train,y_train)\n",
    "        # prediction = knn_best.predict(df_to_predict)\n",
    "        # print('Prediction: {}'.format(prediction))\n",
    "        print('With KNN (K=) accuracy is: ', knn_best.score(X_test,y_test)) # accuracy\n",
    "\n",
    "    #saving and using model\n",
    "    if save_model_file==1:\n",
    "       # Save the model as a pickle in a file\n",
    "        joblib.dump(knn_best, filename)\n",
    "        print('Saved model file as:', filename)\n",
    "\n",
    "\n",
    "    if load_model_and_predict==1:\n",
    "            # Load the model from the file\n",
    "        knn_from_joblib = joblib.load(filename)\n",
    "\n",
    "            # Use the loaded model to make predictions\n",
    "            # modelscorev23.predict_proba(x_test)\n",
    "        knn_from_joblib.predict(df_to_predict)\n",
    "\n",
    "    return knn_from_joblib.predict(df_to_predict)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_k = knn_clf(X_train,X_test,y_train,y_test, detect_best_k=1)[0]\n",
    "best_accuracy = knn_clf(X_train,X_test,y_train,y_test, detect_best_k=1)[1]\n",
    "\n",
    "save_load_predict_model_knn(best_k, best_accuracy, target='TTC_aft',  df_to_predict=X_test,\n",
    "                            train_model=1, save_model_file=1, load_model_and_predict=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#get only prediction\n",
    "save_load_predict_model_knn(best_k,best_accuracy, target='TTC_aft',  df_to_predict=X_test,\n",
    "                            train_model=0, save_model_file=0, load_model_and_predict=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df_done_tasks_5_ml = prepare_df_for_ml(df_tasks_3_t)[0]\n",
    "# df_tasks_4_ml = prepare_df_for_ml(df_tasks_3_t)[1]\n",
    "\n",
    "# MAKING PREDICTIONS ON NOT STARTED TASKS\n",
    "df_tasks_4_ml = df_tasks_4_ml[(df_tasks_4_ml.status == 0)&(df_tasks_4_ml.TTC.notna())]\n",
    "\n",
    "df_tasks_4_ml.drop(columns=['body_last_modified', 'created_datetime', 'completed_datetime', 'subject', 'metricks',\n",
    "                                'task_folder_local_id','original_body_content','duration'], inplace=True, axis=1)\n",
    "\n",
    "df_tasks_4_ml = df_tasks_4_ml.loc[:, col_to_use_to_predict]\n",
    "df_not_started_tasks_4_ml_prediction = df_tasks_4_ml[df_tasks_4_ml.PRI.notna()]\n",
    "\n",
    "#get prediction\n",
    "df_not_started_tasks_4_ml_prediction['TTC_pred'] = save_load_predict_model_knn(best_k, best_accuracy, target='TTC_aft',\n",
    "                             df_to_predict=df_not_started_tasks_4_ml_prediction,\n",
    "                            train_model=0, save_model_file=0, load_model_and_predict=1)\n",
    "\n",
    "# sorting and getting index of tasks to get task names back\n",
    "df_not_started_tasks_4_ml_prediction.sort_values(by=['TTC_pred'], inplace=True, ascending=False)#.index\n",
    "indexes = df_not_started_tasks_4_ml_prediction.index\n",
    "# indexes\n",
    "list_knn_tasks = df_tasks_3.iloc[indexes,0].to_list()\n",
    "list_knn_tasks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# PREDICT PRODUCTIVE HOURS BASED ON 1-DONE TASKS and 2-NUMBER OF SESSIONS PER TIMESLOT\n",
    "\n",
    "def floor_dt(dt, interval=10):\n",
    "    \"\"\"rounding datetime column to 10 min intervals\"\"\"\n",
    "\n",
    "    replace = (dt.minute // interval) * interval\n",
    "    return dt.replace(minute=replace, second=0, microsecond=0)\n",
    "\n",
    "# DB_EMOTIONS_TEST = read_db_paths()[-1]\n",
    "emotions_habits = pd.read_csv(DB_EMOTIONS_TEST)\n",
    "emotions_values, habits_values, emotions_and_habits_values = load_emotions_habits_values()\n",
    "# emotions_habits\n",
    "\n",
    "emotions_habits['datetime'] = emotions_habits.date.astype('str') + ' ' + emotions_habits.time.astype('str')\n",
    "emotions_habits['datetime'] = emotions_habits['datetime'].astype('datetime64')\n",
    "\n",
    "emotions_habits.drop(['date', 'time'], axis=1, inplace=True)\n",
    "emotions_habits['datetime_rnd'] = emotions_habits.datetime.apply(floor_dt)\n",
    "emotions_habits['emo_hab'] = np.where(emotions_habits['act'].isin(emotions_values.keys()), 0, 1)\n",
    "\n",
    "emotions_habits = emotions_habits.groupby('datetime_rnd')['act'].agg(list).reset_index()  # .iloc[1,:]\n",
    "\n",
    "\n",
    "# GENERATION get dummies from list of emotions (act column) grouped by 10min periods\n",
    "emotions_habits = emotions_habits.join(emotions_habits['act'].str.join('|').str.get_dummies())\n",
    "\n",
    "emotions_habits.datetime_rnd = emotions_habits.datetime_rnd.dt.strftime('%Y-%m-%d %H:%M:%S')#.set_index('datetime_rnd')\n",
    "emotions_habits = emotions_habits.drop('act', axis=1)\n",
    "emotions_habits.set_index('datetime_rnd', inplace=True)\n",
    "# print(emotions_habits)\n",
    "\n",
    "\n",
    "def merge_close_timeslots(df):\n",
    "    \"\"\"MERGING THE MOST CLOSE REGISTERED ROWS-TIMESLOTS FOR EMOTIONS HABITS DF\"\"\"\n",
    "    list_of_dd = df.index.to_list()\n",
    "    # print(list_of_dd)\n",
    "\n",
    "    list_of_id_todrop = []\n",
    "    indd=0\n",
    "\n",
    "    for kk in list_of_dd:\n",
    "        if indd+2<=len(list_of_dd):\n",
    "            deltaa=abs(pd.to_datetime(kk) - pd.to_datetime(list_of_dd[indd+1]))\n",
    "            if deltaa < pd.Timedelta('1 hours'):\n",
    "                # print(df.loc[kk])\n",
    "                # print('---')\n",
    "                df.loc[kk] = df.loc[kk] + df.loc[list_of_dd[indd+1]]\n",
    "                list_of_id_todrop.append(list_of_dd[indd+1])\n",
    "\n",
    "                # print(df.loc[list_of_dd[indd+1]])\n",
    "                # print('---')\n",
    "                #\n",
    "                # print(df.loc[kk])\n",
    "                # print(indd, kk, list_of_dd[indd+1]) # for checking\n",
    "            indd+=1\n",
    "    for ki in list_of_id_todrop:\n",
    "        df.drop(ki, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "emotions_habits = merge_close_timeslots(emotions_habits)\n",
    "\n",
    "\n",
    "# MAKING DF FROM SESSIONS\n",
    "def group_by_period(dff):\n",
    "        dff['for_count']=dff['subject'].map(type) == str\n",
    "        #number of sessions per day\n",
    "        number_sessions_per_day = dff.groupby(pd.Grouper(key='start', axis=0,\n",
    "                                             freq='H')).agg({'for_count':sum}).reset_index()\n",
    "\n",
    "        #amount of hours tracked per day\n",
    "        amount_of_hours_tracked_per_day = dff.groupby([pd.Grouper(key='start', axis=0,\n",
    "                                             freq='H'),]).agg({'duration':sum})/ 3600\n",
    "        # number_sessions_per_day.start = number_sessions_per_day.start.astype(str)\n",
    "\n",
    "        out=pd.concat([number_sessions_per_day.set_index('start'),amount_of_hours_tracked_per_day], axis=1).reset_index()\n",
    "        return out\n",
    "\n",
    "df_sessions_for_good = group_by_period(df_sessions)\n",
    "df_sessions_for_good = df_sessions_for_good.rename(columns={'for_count':'amount_sessions', 'start':'datetime_rnd'})\n",
    "df_sessions_for_good = df_sessions_for_good.drop(columns={'duration'})\n",
    "\n",
    "# FROM HERE WE ARE TAKING NUMBER OF SESSIONS IN SPECIFIC TIMESLOTS\n",
    "df_sessions_for_good.datetime_rnd = df_sessions_for_good.datetime_rnd.dt.strftime('%Y-%m-%d %H:%M:%S')#.set_index('datetime_rnd')\n",
    "\n",
    "df_sessions_for_good.set_index('datetime_rnd', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# DETECTING NOT REGISTERED TIME OF WHEN TIME WAS DONE\n",
    "\n",
    "df_sessions1 = df_sessions.groupby(['subject']).agg({'stop': max}).reset_index()\n",
    "\n",
    "df_tasks_3_t_ = df_tasks_3_t.groupby(['completed_datetime']).agg({'subject':\"value_counts\"})\n",
    "# df_tasks_3_t_\n",
    "\n",
    "tasks_done_per_days =  df_tasks_3_t_.groupby(['completed_datetime']).agg({'subject':sum}).reset_index()\n",
    "# tasks_done_per_days\n",
    "\n",
    "# ADDING HOURS MINUTES TO TASK_DONE DF BASED ON TIMESTAMPS IN EMOTIONS DF\n",
    "import random\n",
    "def add_random_hours_min(k):\n",
    "    # detecting timeslots in emotions habits df to JOIN on them later\n",
    "    list_of_timeslots = emotions_habits.reset_index().datetime_rnd.astype('datetime64').dt.strftime(\"%H:%M:%S\").unique()\n",
    "    return k +' '+ np.random.choice(list_of_timeslots)\n",
    "\n",
    "tasks_done_per_days.completed_datetime = tasks_done_per_days.completed_datetime.astype(str).apply(lambda x:\n",
    "                                                                                                add_random_hours_min(x))\n",
    "tasks_done_per_days.completed_datetime = tasks_done_per_days.completed_datetime.astype('datetime64')\n",
    "tasks_done_per_days = tasks_done_per_days.rename(columns={'completed_datetime':'datetime_rnd','subject':'tasks_done'})\n",
    "tasks_done_per_days = tasks_done_per_days.set_index('datetime_rnd')\n",
    "\n",
    "\n",
    "def find_nearest_date(df1, df_emo):\n",
    "    \"\"\"\n",
    "    finding nearest date in df_emo and write it to df1\n",
    "\n",
    "    #TODO too many times reseting the index. but now pipeline used in inner functions\n",
    "\n",
    "    :param df1: df of sessions with generated hours minutes\n",
    "    :param df_emo: emotions habits dataframe\n",
    "    :return: df with changed time\n",
    "    \"\"\"\n",
    "\n",
    "    df1 = df1.reset_index()\n",
    "    df_emo = df_emo.reset_index()\n",
    "    df1.datetime_rnd = df1.datetime_rnd.astype('datetime64')\n",
    "    df_emo.datetime_rnd = df_emo.datetime_rnd.astype('datetime64')\n",
    "\n",
    "    df2 = df1.copy() #CONTroVERSIVE\n",
    "\n",
    "    # return df1.datetime_rnd\n",
    "    for i in df2.datetime_rnd:\n",
    "        # print(i)\n",
    "        minidx_ = abs(i - df_emo['datetime_rnd']).argmin()\n",
    "        delta = abs(i - df_emo.loc[minidx_,'datetime_rnd'])\n",
    "        # print(i, df_emo.loc[[minidx_]]['datetime_rnd'] , delta, delta/pd.Timedelta('1 hour'))\n",
    "\n",
    "        if delta/pd.Timedelta('1 hour') < 5:\n",
    "            index = df2.index[df2.datetime_rnd==i]\n",
    "            # print(df1.loc[index, 'datetime_rnd'])\n",
    "            # print('BEFORE',df_emo.loc[minidx_,'datetime_rnd'])\n",
    "            df2.loc[index, 'datetime_rnd'] = df_emo.loc[minidx_,'datetime_rnd']\n",
    "            # print('CHANGE', df1.loc[index, 'datetime_rnd'])\n",
    "\n",
    "        # print()\n",
    "        # print(df_emo.loc[[minidx_]])\n",
    "    return df2\n",
    "\n",
    "\n",
    "\n",
    "df_sessions_for_good_ = find_nearest_date(df_sessions_for_good, emotions_habits)\n",
    "tasks_done_per_days_ = find_nearest_date(tasks_done_per_days, emotions_habits)\n",
    "\n",
    "#summing up duplicates\n",
    "df_sessions_for_good_ = df_sessions_for_good_.reset_index().groupby('datetime_rnd').agg({'amount_sessions': sum})\n",
    "\n",
    "#just test\n",
    "# df_sessions_for_good_[df_sessions_for_good_.datetime_rnd=='2022-08-09 10:50:00']\n",
    "# df_sessions_for_good_[df_sessions_for_good_.amount_sessions>0]\n",
    "\n",
    "\n",
    "# df_sessions_for_good_ = df_sessions_for_good_.set_index('datetime_rnd')\n",
    "# tasks_done_per_days_ = tasks_done_per_days_.set_index('datetime_rnd')\n",
    "\n",
    "\n",
    "\n",
    "emotions_habits_t = emotions_habits.reset_index().copy()\n",
    "emotions_habits_t.datetime_rnd = emotions_habits_t.datetime_rnd.astype(str)\n",
    "\n",
    "tasks_done_per_days_.datetime_rnd = tasks_done_per_days_.datetime_rnd.astype(str)\n",
    "# emotions_habits_t\n",
    "\n",
    "df_sessions_for_good_t = df_sessions_for_good_.reset_index().copy()\n",
    "df_sessions_for_good_t.datetime_rnd = df_sessions_for_good_t.datetime_rnd.astype(str)\n",
    "\n",
    "#MERGING ALL together\n",
    "df_final_ = emotions_habits_t.merge(tasks_done_per_days_, how='left', on='datetime_rnd')\n",
    "df_final = df_final_.merge(df_sessions_for_good_t, how='left', on='datetime_rnd')\n",
    "\n",
    "\n",
    "# df_final_ = pd.concat([emotions_habits, tasks_done_per_days_], axis = 1)\n",
    "# df_final = pd.concat([df_final_, df_sessions_for_good_], axis = 1)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def correlation_matrix_for_emohabits():\n",
    "    corr = df_final.corr()\n",
    "    corr.style.background_gradient(cmap='coolwarm')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(rc = {'figure.figsize':(21,15)})\n",
    "sns.heatmap(df_final.corr())\n",
    "\n",
    "plt.savefig(\"Plotting_Correlation_HeatMap.jpg\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.imshow(df_final,text_auto=True)\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Usage:\n",
    "# e.g. print_highly_correlated(df=model, features=model.columns)\n",
    "\n",
    "def print_highly_correlated(df, features, threshold=0.3):\n",
    "    \"\"\"Prints highly correlated features pairs in the data frame (helpful for feature engineering)\"\"\"\n",
    "    corr_df = df[features].corr() # get correlations\n",
    "    correlated_features = np.where(np.abs(corr_df) > threshold) # select ones above the abs threshold\n",
    "    correlated_features = [(corr_df.iloc[x,y], x, y) for x, y in zip(*correlated_features) if x != y and x < y] # avoid duplication\n",
    "    s_corr_list = sorted(correlated_features, key=lambda x: -abs(x[0])) # sort by correlation value\n",
    "\n",
    "    if s_corr_list == []:\n",
    "        print(\"There are no highly correlated features with correlation above\", threshold)\n",
    "    else:\n",
    "        for vv, ii, jj in s_corr_list:\n",
    "            cols = df[features].columns\n",
    "            print (\"%s and %s = %.3f\" % (corr_df.index[ii], corr_df.columns[jj], vv))\n",
    "\n",
    "# pairs of highly correlated features\n",
    "print_highly_correlated(df=df_final, features=df_final.columns)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_final#.info()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# dropping 'tasks_done' because too small amount\n",
    "col_to_use2 = ['+fear', '+sadness', '+surprise', '+youtubed', '-fear',\n",
    "       '-sadness', '-surprise',  '10 pushups everyday',\n",
    "       '5 minute journal', 'Full-time', 'Part-time',\n",
    "       'UNPREDICTABLE EMOTIONAL WOWs', 'admiration', 'amusement', 'anger',\n",
    "       'anxiety', 'any pain', 'appreciation', 'arguing',\n",
    "       'big physical activity', 'boredom', 'burnouted', 'cafe', 'calmness',\n",
    "       'chess', 'cold shower', 'common goals completion', 'confusion',\n",
    "       'critiqued_by_HER', 'critiqued_by_ME', 'desire', 'disgust',\n",
    "       'dissatisfaction', 'drugs', 'embarrassed', 'emotionally UNbalanced',\n",
    "       'emotionally balanced', 'empathic', 'excitement', 'fascination',\n",
    "       'fastfood', 'film', 'financial reduce costs', 'focused', 'happiness',\n",
    "       'inspiration', 'interest', 'joy', 'jrk', 'languages',\n",
    "       'look inside 4 feelings on whole life', 'made smth for selfefficiency',\n",
    "       'meditation', 'motivated', 'new people', 'new sex partner', 'nostalgia',\n",
    "       'old_friends', 'opensourced questions answered', 'over_eated', 'pain',\n",
    "       'pleasure from done tasks', 'porn', 'pride', 'procrastinated',\n",
    "       'productive', 'psycho practices', 'reading', 'relief', 'romance',\n",
    "       'running on plans feeling', 'satisfaction', 'sex', 'sexual desire',\n",
    "       'slept_GOOD', 'social offline', 'studing', 'surprise', 'too much news',\n",
    "       'too much social media', 'too much youtube', 'traveled', 'tvshow',\n",
    "       'work thru complicated situations', 'Не можу працювати',\n",
    "        'day', 'hour', 'moon_phase']\n",
    "\n",
    "col_to_predict2_positive = [ 'amount_sessions', '+surprise','amusement', 'drugs',\n",
    "                             'emotionally balanced','focused', 'happiness','motivated',\n",
    "                             'new people','pleasure from done tasks', 'pride',\n",
    "                             'productive','running on plans feeling',]\n",
    "\n",
    "col_to_predict2_negative = [ 'burnouted', 'Не можу працювати', 'anxiety', 'any pain',\n",
    "                             'confusion','emotionally UNbalanced','procrastinated',]\n",
    "\n",
    "cols_to_drop2 = ['datetime_rnd', '0-2', '5-7', '8-10', '2-5','tasks_done',]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prepare_emohab_2_for_ML_knn(df_final):\n",
    "    def moon_phase(datetime_=None):\n",
    "        \"\"\"\n",
    "        https://gist.github.com/miklb/ed145757971096565723\n",
    "        :return: 1 out of 8  moon phases\n",
    "        \"\"\"\n",
    "        import math, decimal, datetime\n",
    "        dec = decimal.Decimal\n",
    "\n",
    "        def position(now=None):\n",
    "           if now is None:\n",
    "              now = datetime.datetime.now()\n",
    "\n",
    "           diff = now - datetime.datetime(2001, 1, 1)\n",
    "           days = dec(diff.days) + (dec(diff.seconds) / dec(86400))\n",
    "           lunations = dec(\"0.20439731\") + (days * dec(\"0.03386319269\"))\n",
    "\n",
    "           return lunations % dec(1)\n",
    "\n",
    "        def phase(pos):\n",
    "           index = (pos * dec(8)) + dec(\"0.5\")\n",
    "           index = math.floor(index)\n",
    "           return index\n",
    "           # return {\n",
    "           #    0: \"New Moon\",\n",
    "           #    1: \"Waxing Crescent\",\n",
    "           #    2: \"First Quarter\",\n",
    "           #    3: \"Waxing Gibbous\",\n",
    "           #    4: \"Full Moon\",\n",
    "           #    5: \"Waning Gibbous\",\n",
    "           #    6: \"Last Quarter\",\n",
    "           #    7: \"Waning Crescent\"\n",
    "           # }[int(index) & 7]\n",
    "\n",
    "        pos = position(datetime_)\n",
    "        phasename = phase(pos)\n",
    "\n",
    "        roundedpos = round(float(pos), 3)\n",
    "        # print (\"%s (%s)\" % (phasename, roundedpos))\n",
    "        return phasename\n",
    "\n",
    "\n",
    "    #preparing df for ML\n",
    "    df_hab_emo_for_ML = df_final.copy()\n",
    "    df_hab_emo_for_ML['day'] = df_hab_emo_for_ML.datetime_rnd.astype('datetime64').dt.day_of_week\n",
    "    df_hab_emo_for_ML['hour'] = df_hab_emo_for_ML.datetime_rnd.astype('datetime64').dt.hour\n",
    "\n",
    "    #making moonphases\n",
    "    df_hab_emo_for_ML['moon_phase'] = df_hab_emo_for_ML.datetime_rnd.apply(lambda x: moon_phase(pd.to_datetime(x)))\n",
    "\n",
    "    #merging to 1 categorical column\n",
    "    df_hab_emo_for_ML['common_energy'] = df_hab_emo_for_ML['0-2'] + 2*df_hab_emo_for_ML['2-5']\\\n",
    "                                         + 3*df_hab_emo_for_ML['5-7']  + 4*df_hab_emo_for_ML['8-10']\n",
    "\n",
    "    #dropping cols\n",
    "    for kil in cols_to_drop2:\n",
    "        df_hab_emo_for_ML.drop(kil,axis=1,inplace=True)\n",
    "\n",
    "    #converting to categorical\n",
    "    for convo in col_to_use2:\n",
    "        df_hab_emo_for_ML[convo] = df_hab_emo_for_ML[convo].astype('category')\n",
    "    return df_hab_emo_for_ML\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_hab_emo_for_ML = prepare_emohab_2_for_ML_knn(df_final)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_hab_emo_for_ML\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# or how emotions influence(?) on amount of sessions?\n",
    "#KNN prediction for 'amount_sessions'\n",
    "df_hab_emo_for_ML = prepare_emohab_2_for_ML_knn(df_final)\n",
    "\n",
    "X,y = df_hab_emo_for_ML.loc[:, col_to_use2], df_hab_emo_for_ML.loc[:,'amount_sessions']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state = 2022)\n",
    "\n",
    "best_kk = knn_clf(X_train,X_test,y_train,y_test, detect_best_k=1)[0]\n",
    "best_accuracy_ = knn_clf(X_train,X_test,y_train,y_test, detect_best_k=1)[1]\n",
    "\n",
    "filename = 'amount_sessions' + '_' + str(best_k) + '_' + str(best_accuracy_) + '.pkl'\n",
    "print('Saved model file as:', filename)\n",
    "\n",
    "knn_best = KNeighborsClassifier(n_neighbors=best_kk)\n",
    "knn_best.fit(X_train,y_train)\n",
    "print('With KNN (K=) accuracy is: ', knn_best.score(X_test,y_test)) # accuracy\n",
    "\n",
    "# saving and using model\n",
    "# Save the model as a pickle in a file\n",
    "joblib.dump(knn_best, filename)\n",
    "\n",
    "# Load the model from the file\n",
    "knn_from_joblib = joblib.load(filename)\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "# modelscorev23.predict_proba(x_test)\n",
    "knn_from_joblib.predict(X_test)\n",
    "\n",
    "# TODO fix later\n",
    "# get predictions how many work sessions i will make, based on habits emotions\n",
    "df_not_started_tasks_4_ml_prediction['TTC_pred'] = save_load_predict_model_knn(\n",
    "                                                                               best_kk, best_accuracy_,\n",
    "                                                                               target='amount_sessions',\n",
    "                                                                               df_to_predict=df_hab_emo_for_ML,\n",
    "                                                                               train_model=0, save_model_file=0,\n",
    "                                                                               load_model_and_predict=1)\n",
    "\n",
    "# sorting and getting index of tasks to get task names back\n",
    "df_not_started_tasks_4_ml_prediction.sort_values(by=['amount_sessions'], inplace=True, ascending=False)  # .index\n",
    "indexes = df_not_started_tasks_4_ml_prediction.index\n",
    "# indexes\n",
    "list_knn_tasks = df_tasks_3.iloc[indexes, 0].to_list()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import (AutoARIMA, SeasonalNaive, Naive,\n",
    "    RandomWalkWithDrift, HistoricAverage )\n",
    "\n",
    "#TIMESERIES PREDICTION FOR EMOTION HABITS DF\n",
    "# https://colab.research.google.com/github/Nixtla/statsforecast/blob/main/nbs/examples/UncertaintyIntervals.ipynb\n",
    "\n",
    "def plot_grid(df_train, df_test=None, plot_random=True, model=None, level=None):\n",
    "    from itertools import product\n",
    "\n",
    "    fig, axes = plt.subplots(4, 2, figsize = (24, 14))\n",
    "\n",
    "    unique_ids = df_train['unique_id'].unique()\n",
    "\n",
    "    assert len(unique_ids) >= 8, \"Must provide at least 8 ts\"\n",
    "\n",
    "    if plot_random:\n",
    "        unique_ids = random.sample(list(unique_ids), k=8)\n",
    "    else:\n",
    "        unique_ids = unique_ids[:8]\n",
    "\n",
    "    for uid, (idx, idy) in zip(unique_ids, product(range(4), range(2))):\n",
    "        train_uid = df_train.query('unique_id == @uid')\n",
    "        axes[idx, idy].plot(train_uid['ds'], train_uid['y'], label = 'y_train')\n",
    "        if df_test is not None:\n",
    "            max_ds = train_uid['ds'].max()\n",
    "            test_uid = df_test.query('unique_id == @uid')\n",
    "            for col in ['y', model, 'y_test']:\n",
    "                if col in test_uid:\n",
    "                    axes[idx, idy].plot(test_uid['ds'], test_uid[col], label=col)\n",
    "            if level is not None:\n",
    "                for l, alpha in zip(sorted(level), [0.5, .4, .35, .2]):\n",
    "                    axes[idx, idy].fill_between(\n",
    "                        test_uid['ds'],\n",
    "                        test_uid[f'{model}-lo-{l}'],\n",
    "                        test_uid[f'{model}-hi-{l}'],\n",
    "                        alpha=alpha,\n",
    "                        color='orange',\n",
    "                        label=f'{model}_level_{l}',\n",
    "                    )\n",
    "        axes[idx, idy].set_title(f'M4 Hourly: {uid}')\n",
    "        axes[idx, idy].set_xlabel('Timestamp [t]')\n",
    "        axes[idx, idy].set_ylabel('Target')\n",
    "        axes[idx, idy].legend(loc='upper left')\n",
    "        axes[idx, idy].xaxis.set_major_locator(plt.MaxNLocator(20))\n",
    "        axes[idx, idy].grid()\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "train_days_on = '2 days'\n",
    "\n",
    "df_for_timeseries = df_final.copy().set_index('datetime_rnd') #.iloc[:,5:14]\n",
    "\n",
    "\n",
    "# filtering and dropping too small data columns\n",
    "drop_level = 10\n",
    "to_drop = []\n",
    "for i in df_for_timeseries.columns:\n",
    "    if df_for_timeseries[i].value_counts()[1]<drop_level:\n",
    "        to_drop.append(i)\n",
    "\n",
    "for kl in to_drop:\n",
    "    df_for_timeseries.drop(columns={kl},inplace=True)\n",
    "\n",
    "# how many features left after dropping\n",
    "number_of_series = df_for_timeseries.shape[1]\n",
    "\n",
    "df_for_timeseries = df_for_timeseries.stack().reset_index()\n",
    "\n",
    "df_for_timeseries = df_for_timeseries.rename(columns={'level_1': 'unique_id', 0: 'y', 'datetime_rnd': 'ds'})\n",
    "\n",
    "# onehotencoding\n",
    "# df_for_timeseries.unique_id = df_for_timeseries.unique_id.astype('category').cat.codes#pd.factorize(df_for_timeseries.unique_id)[0]\n",
    "\n",
    "# df_for_timeseries = df_for_timeseries.set_index('unique_id')\n",
    "df_for_timeseries.ds = df_for_timeseries.ds.astype('datetime64')\n",
    "\n",
    "\n",
    "# how  many days to take for train set\n",
    "dayx = pd.to_datetime(df_for_timeseries.ds.max().strftime('%Y-%m-%d')) - pd.Timedelta(train_days_on)\n",
    "\n",
    "Y_train_df = df_for_timeseries[df_for_timeseries.ds < dayx]\n",
    "Y_test_df = df_for_timeseries[df_for_timeseries.ds > dayx]\n",
    "\n",
    "n_series = number_of_series\n",
    "uids = Y_train_df['unique_id'].unique()[:n_series]\n",
    "train = Y_train_df.query('unique_id in @uids')\n",
    "test = Y_test_df.query('unique_id in @uids')\n",
    "# train\n",
    "\n",
    "# plot_grid(train, test)\n",
    "\n",
    "\n",
    "models = [\n",
    "    AutoARIMA(season_length=24, approximation=True),\n",
    "    Naive(),\n",
    "    SeasonalNaive(season_length=24),\n",
    "    RandomWalkWithDrift(),\n",
    "    HistoricAverage()\n",
    "]\n",
    "\n",
    "fcst = StatsForecast(df=train,\n",
    "                     models=models,\n",
    "                     freq='H',\n",
    "                     n_jobs=-1)\n",
    "\n",
    "\n",
    "#setting levels of probability\n",
    "levels = [95, 99]\n",
    "forecasts = fcst.forecast(h=48, level=levels)\n",
    "forecasts = forecasts.reset_index()\n",
    "forecasts.head()\n",
    "\n",
    "test = test.merge(forecasts, how='left', on=['unique_id', 'ds'])\n",
    "\n",
    "# plot_grid(train, test, level=levels, model='AutoARIMA')\n",
    "# plot_grid(train, test, level=levels, model='SeasonalNaive')\n",
    "# plot_grid(train, test, level=levels, model='HistoricAverage')\n",
    "# plot_grid(train, test, level=levels, model='Naive')\n",
    "# plot_grid(train, test, level=levels, model='RWD')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test.head(100)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DecisionTree\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "col_to_use_to_predict = ['importance', 'group', 'life_area', 'TTC', 'PRI', 'PLEAS', 'DIFF', 'RESIS',\n",
    "    'created_datetime_numday'] #, 'body_last_modified_numday', 'modified_minus_created_dayscount'\n",
    "\n",
    "col_to_predict = ['motivation', 'TTC_aft', 'PRI_aft', 'PLEASURE_aft', 'DIFCLT_aft', 'RES_aft',\n",
    "                      'underrated', 'completed_datetime_numday','completed_minus_created_dayscount']\n",
    "\n",
    "\n",
    "\n",
    "    # scaler = MinMaxScaler()\n",
    "    # df_done_tasks_5_ml[['PRI', 'DIFF','PLEAS','RESIS']] = scaler.fit_transform(df_done_tasks_5_ml[['PRI', 'DIFF','PLEAS',\n",
    "    # 'RESIS']])\n",
    "\n",
    "    # TTC_aft underrated completed_datetime_numday\n",
    "\n",
    "X,y = df_done_tasks_5_ml.loc[:, col_to_use_to_predict], df_done_tasks_5_ml.loc[:,'TTC_aft']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state = 2022)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "\n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    \"criterion\":(\"gini\", \"entropy\"),\n",
    "    \"splitter\":(\"best\", \"random\"),\n",
    "    \"max_depth\":(list(range(1, 20))),\n",
    "    \"min_samples_split\":[2, 3, 4],\n",
    "    \"min_samples_leaf\":list(range(1, 20)),\n",
    "}\n",
    "\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_cv = GridSearchCV(tree_clf, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=3)\n",
    "tree_cv.fit(X_train, y_train)\n",
    "best_params = tree_cv.best_params_\n",
    "print(f\"Best paramters: {best_params})\")\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(**best_params)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forrest\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=20)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Random Forest hyperparameter tuning\n",
    "# a) Randomized Search Cross Validation¶\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators, 'max_features': max_features,\n",
    "               'max_depth': max_depth, 'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap}\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_cv = RandomizedSearchCV(estimator=rf_clf, scoring='f1',param_distributions=random_grid, n_iter=100, cv=3,\n",
    "                               verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "rf_cv.fit(X_train, y_train)\n",
    "rf_best_params = rf_cv.best_params_\n",
    "print(f\"Best paramters: {rf_best_params})\")\n",
    "\n",
    "rf_clf = RandomForestClassifier(**rf_best_params)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Grid Search Cross Validation\n",
    "\n",
    "n_estimators = [100, 500, 1000, 1500]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [2, 3, 5]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4, 10]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "params_grid = {'n_estimators': n_estimators, 'max_features': max_features,\n",
    "               'max_depth': max_depth, 'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap}\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_cv = GridSearchCV(rf_clf, params_grid, scoring=\"f1\", cv=3, verbose=2, n_jobs=-1)\n",
    "\n",
    "\n",
    "rf_cv.fit(X_train, y_train)\n",
    "best_params = rf_cv.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "rf_clf = RandomForestClassifier(**best_params)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=False)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tune_sklearn import TuneSearchCV\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "col_to_use_to_predict = ['status', 'importance', 'group', 'life_area', 'TTC', 'PRI', 'PLEAS', 'DIFF', 'RESIS',\n",
    "'created_datetime_numday']\n",
    "\n",
    "col_to_predict = ['motivation', 'TTC_aft', 'PRI_aft', 'PLEASURE_aft', 'DIFCLT_aft', 'RES_aft',\n",
    "                  'underrated', 'completed_datetime_numday','completed_minus_created_dayscount']\n",
    "\n",
    "\n",
    "    # Split df into X and y\n",
    "X = df_done_tasks_5_ml.loc[:, col_to_use_to_predict]\n",
    "y = df_done_tasks_5_ml.loc[:,'TTC_aft']\n",
    "\n",
    "    # Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.3, shuffle=True, random_state=2022)\n",
    "\n",
    "# model = DecisionTreeRegressor()\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "    # Get results\n",
    "result = model.score(X_test, y_test)\n",
    "\n",
    "print(result)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def neg_rmsle_custom(y_true_two_trans, y_pred_two):\n",
    "  try:\n",
    "    score = np.negative(mean_squared_error(np.log1p(np.expm1(y_true_two_trans).sum(axis=1)),\n",
    "                                         np.log1p(np.expm1(np.maximum(y_pred_two, 0)).sum(axis=1)), squared=False))\n",
    "  except:\n",
    "    score = np.nan\n",
    "  return score\n",
    "\n",
    "target_metric = make_scorer(neg_rmsle_custom, greater_is_better=True)\n",
    "\n",
    "\n",
    "model_list = []\n",
    "for name in ['linear', 'svm', 'rf', 'xgb', 'mlp', 'fm']:\n",
    "  model_list.append(np.full(5, name))\n",
    "\n",
    "best_cv_df = pd.DataFrame({'model': np.hstack((model_list)), 'RMSLE':None, 'best_hyper_param':None})\n",
    "\n",
    "\n",
    "X_trainee = df_done_tasks_5_ml.loc[:, col_to_use_to_predict]\n",
    "yy = df_done_tasks_5_ml.loc[:,['TTC_aft']]#col_to_predict\n",
    "\n",
    "\n",
    "y_train_two = yy.values.astype(np.float32)\n",
    "\n",
    "y_train_two_trans = np.log1p(y_train_two)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Random forest¶\n",
    "from tune_sklearn import TuneGridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# Define a search space\n",
    "parameters = {\n",
    "    'estimator__n_estimators': [30, 100],\n",
    "    'estimator__criterion': ['squared_error'],\n",
    "    'estimator__max_depth': [25, 30, 35],\n",
    "    'estimator__max_features': ['auto'],\n",
    "    'estimator__random_state': [2022]\n",
    "}\n",
    "\n",
    "# Define a Multi-output regressor\n",
    "base_regr = RandomForestRegressor()\n",
    "regressor = MultiOutputRegressor(base_regr)\n",
    "\n",
    "# Specify a hyper parameter tuning algorithm\n",
    "tune_search = TuneSearchCV(\n",
    "    regressor,\n",
    "    parameters,\n",
    "    search_optimization='hyperopt',\n",
    "    n_trials=6,\n",
    "    n_jobs=-1,\n",
    "    scoring={'RMSLE':target_metric},\n",
    "    cv=5,\n",
    "    refit='RMSLE',\n",
    "    verbose=1,\n",
    "    random_state=2022\n",
    "    )\n",
    "\n",
    "# Run hyper parameter tuning\n",
    "X = X_trainee\n",
    "y = y_train_two_trans\n",
    "tune_search.fit(X, y)\n",
    "\n",
    "# Save the tuning results\n",
    "model_name = 'rf'\n",
    "\n",
    "## Save the optimal hyper parmater values\n",
    "best_cv_df.loc[best_cv_df['model']==model_name, 'best_hyper_param'] = str(tune_search.best_params_)\n",
    "\n",
    "## Save the CV results\n",
    "cv_df = pd.DataFrame(tune_search.cv_results_)\n",
    "cv_values = cv_df.loc[tune_search.best_index_, cv_df.columns.str.startswith('split')].values\n",
    "best_cv_df.loc[best_cv_df['model']==model_name, 'RMSLE'] = cv_values[:5]\n",
    "\n",
    "# Visualize the tuning results with parallel coordinate plot\n",
    "tune_result_df = pd.concat([pd.DataFrame(tune_search.cv_results_['params']), cv_df.loc[:,cv_df.columns.str.startswith('mean')] ], axis=1)\n",
    "import plotly.express as px\n",
    "px.parallel_coordinates(tune_result_df, color='mean_test_RMSLE')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "number_hard_tasks_per_m(df_tasks_3_t).iloc[:,:1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TODO WTFFFFF\n",
    "check_goals_difficulty(df_tasks_3_t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tasks_done_per_month(df_tasks_3_t).iloc[:,:1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "amount_tasks_done_life_areas(df_tasks_3_t).iloc[:,:1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "amount_complited_tasks_permonth(df_tasks_3_t).iloc[:,:1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "amount_complited_tasks_per_list_month(df_tasks_3_t, 'BACKLOG life').iloc[:,:1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#creativity??? sparks\n",
    "amount_new_tasks_per_day(df_tasks_3_t)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# # DROP\n",
    "# df_tasks_4_ml.drop(columns='task_folder_local_id',inplace=True, axis=1)\n",
    "# # WTF why there are 2 of them\n",
    "# df_tasks_4_ml.drop(columns='original_body_content',inplace=True, axis=1)\n",
    "# # df_tasks_4_ml.drop(df_tasks_4_ml.columns[[5]],axis = 1,inplace=True)\n",
    "# # df_tasks_4_ml.original_body_content.nunique()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Working with getdummies and categorial features\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.get_dummies(obj_df, columns=[\"body_style\", \"drive_wheels\"], prefix=[\"body\", \"drive\"]).head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#get all categorical columns\n",
    "cat_columns = df.select_dtypes(['object']).columns\n",
    "\n",
    "#convert all categorical columns to numeric\n",
    "df[cat_columns] = df[cat_columns].apply(lambda x: pd.factorize(x)[0])\n",
    "\n",
    "\n",
    "df['col2'] = df['col2'].astype('category')\n",
    "\n",
    "df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cleanup_nums = {\"num_doors\":     {\"four\": 4, \"two\": 2},\n",
    "                \"num_cylinders\": {\"four\": 4, \"six\": 6, \"five\": 5, \"eight\": 8,\n",
    "                                  \"two\": 2, \"twelve\": 12, \"three\":3 }}\n",
    "\n",
    "To convert the columns to numbers using replace :\n",
    "\n",
    "obj_df = obj_df.replace(cleanup_nums)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "day_starts = 11\n",
    "day_ends = 0\n",
    "\n",
    "###############LOGIC\n",
    "# 0.DONE detect by stats timewindows for best work,  and dinner. and walk outdoors\n",
    "# 1.DONE detect area balance by week.\n",
    "# 2.DONE detect witch areas are 'weak'\n",
    "# 3.DONE sort tasks from each life area (make lists) from these areas by\n",
    "#     - most resistance, most priority, most pleasure [MOST PLEASUREFUL]\n",
    "#     - least resistance, least TTC, most pleasure  [EASY]\n",
    "#     - most priority, most difficulty, most TTC  [MOST DIFFICULT]\n",
    "# 4.DONE iterate by this lists.\n",
    "# 5.DONE sometimes random\n",
    "# 6.TODO recommend career tasks at the daytime\n",
    "# 7.TODO make habits as recurring tasks, to include them to recommendation\n",
    "# 8.TODO make morning routine\n",
    "# 9.TODO make evening routine\n",
    "# 10.TODO add tasks to calendar (maybe not all the day) up to next window end (input of emotions)\n",
    "# make breaks  in tasks???\n",
    "# 11.TODO sync recalculation of recommendation moments of emotion input\n",
    "# 12.TODO add special very TASTY tasks (wishlist type, or bucketlist) to calendar somewhere in a week\n",
    "#\n",
    "#\n",
    "# ############ MAYBE\n",
    "# - Morning the most hated task (with most RES, but least by DIFF)\n",
    "# - midday slow easy short\n",
    "# - dinner fun social (or media) smth\n",
    "# - afternoon mid - heavy mid short task\n",
    "# - dinner fun or recreation or relation smth\n",
    "# - midnight sex relax or intelligent.\n",
    "\n",
    "def count_balance_of_life_areas_tasks_habits(df_tasks_3_t):\n",
    "    \"\"\"counting balance by life areas summing tasks and habits\"\"\"\n",
    "\n",
    "\n",
    "    habits_values = load_emotions_habits_values()[1]\n",
    "    result = {'PHYSICAL':0, 'FUN_RECREATION':0, 'INTELECTUAL':0, 'LOVE ROMANCE SEX':0, 'PARTNER':0, 'SOCIAL FRIENDS':0,\n",
    "             'FINANCIAL':0, 'CAREER':0}\n",
    "\n",
    "    # last week counting tasks by life area name from todo tasks and registered habits\n",
    "    for i in result.keys():\n",
    "        #cheking if there are any completed tasks in this area\n",
    "        if amount_complited_tasks_per_area_week(df_tasks_3_t, i).index[-1][0]:\n",
    "            # print(i)\n",
    "            number_area_tasks_weekly = amount_complited_tasks_per_area_week(df_tasks_3_t, i).iloc[-1,0]\n",
    "            # print(number_area_tasks_weekly)\n",
    "            result[i]+=number_area_tasks_weekly\n",
    "\n",
    "    #list of habits done last week\n",
    "    list_of_last_week_habits = df_habits.groupby(pd.Grouper(key='datetime_rnd', axis=0, freq='W')).agg({\"act\": lambda x:\n",
    "    list(x)}).iloc[-1,0]\n",
    "    # print(list_of_last_week_habits)\n",
    "    for k in list_of_last_week_habits:\n",
    "        # print(k)\n",
    "        # print(habits_values.values())\n",
    "        for kk in habits_values.values():\n",
    "            # print(kk.keys())\n",
    "            if k in kk.keys():\n",
    "                r = {i for i in habits_values if habits_values[i] == kk}\n",
    "                r=''.join(r)\n",
    "                # print(r)\n",
    "                result[r] +=1\n",
    "\n",
    "    df_balance = pd.DataFrame.from_dict(result, orient='index').reset_index()\n",
    "    df_balance.columns.values[1] = 'amount'\n",
    "    df_balance.sort_values(by=['amount'], inplace=True, ascending=True)\n",
    "\n",
    "    #DF OF AREAS LESS THAN MEAN COMPARING WITH OTHER AREAS\n",
    "    list_of_forgotten_areas = df_balance[df_balance.amount < df_balance.amount.mean()]['index']\n",
    "    list_of_most_active_areas = df_balance[df_balance.amount > df_balance.amount.mean()]['index']\n",
    "\n",
    "    return list_of_forgotten_areas, list_of_most_active_areas\n",
    "\n",
    "\n",
    "\n",
    "#choose if metricks col is not empty\n",
    "def return_tasks_list_by(df_tasks_3_t, life_area):\n",
    "    \"\"\"sort tasks from each life area (make lists) from these areas by\n",
    "        - most resistance, most priority, most pleasure [MOST PLEASUREFUL]\n",
    "        - least resistance, least TTC, most pleasure  [EASY]\n",
    "        - most priority, most difficulty, most TTC  [MOST DIFFICULT]\"\"\"\n",
    "\n",
    "\n",
    "    if df_tasks_3_t[(df_tasks_3_t.metricks.notna()) & (df_tasks_3_t.life_area == life_area)].shape[0]==0 or \\\n",
    "            df_tasks_3_t[df_tasks_3_t['life_area']== life_area].shape[0]==0:\n",
    "        return df_tasks_3_t[df_tasks_3_t['life_area']== life_area]#.sample(n=3) # 3 random rows from list\n",
    "    else:\n",
    "        most_pleasureful_tasks_list = df_tasks_3_t[(df_tasks_3_t['life_area']== life_area)& (df_tasks_3_t['status']!=\n",
    "                                                                                      'NotStarted')].sort_values\\\n",
    "            (by=['RESIS','PRI','PLEAS'],ascending=[False,False,False]).subject.head(3).tolist()\n",
    "        most_easy_tasks_list = df_tasks_3_t[(df_tasks_3_t['life_area']== life_area)& (df_tasks_3_t['status']!=\n",
    "                                                                                      'NotStarted')].sort_values(by=['RESIS',\n",
    "                                                                                                          'TTC',\n",
    "                                                                                                          'PLEAS'],\n",
    "                                                                         ascending=[True,True,False]).subject.head(3).tolist()\n",
    "        most_difficult_tasks_list = df_tasks_3_t[(df_tasks_3_t['life_area']== life_area)& (df_tasks_3_t['status']!=\n",
    "                                                                                      'NotStarted')].sort_values(by=['PRI',\n",
    "                                                                                                          'DIFF',\n",
    "                                                                                                          'TTC'],\n",
    "                                                                         ascending=[False,False,False]).subject.head(3).tolist()\n",
    "        return most_pleasureful_tasks_list, most_easy_tasks_list, most_difficult_tasks_list\n",
    "\n",
    "#recomend most forgotten areas\n",
    "# for iii in count_balance_of_life_areas_tasks_habits(df_tasks_3_t)[0]:\n",
    "#     print(return_tasks_list_by(df_tasks_3_t, iii))\n",
    "\n",
    "#recomend least forgotten areas\n",
    "for iii in count_balance_of_life_areas_tasks_habits(df_tasks_3_t)[1]:\n",
    "    print(iii)\n",
    "    print(return_tasks_list_by(df_tasks_3_t, iii))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# number_tasks_per_day_per_task(df_tasks_3_t)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#SAVINGmodel\n",
    "# import pickle\n",
    "\n",
    "# Save the trained model as a pickle string.\n",
    "# saved_model = pickle.dumps(knn)\n",
    "#\n",
    "# # Load the pickled model\n",
    "# knn_from_pickle = pickle.loads(saved_model)\n",
    "#\n",
    "# # Use the loaded pickled model to make predictions\n",
    "# knn_from_pickle.predict(x_test)\n",
    "\n",
    "#\n",
    "#\n",
    "# model = knn() # put yours model\n",
    "# model.fit(X_train, Y_train)\n",
    "#\n",
    "# # save the model to disk\n",
    "# filename = 'finalized_model.sav'\n",
    "# pickle.dump(model, open(filename, 'wb'))\n",
    "#\n",
    "#\n",
    "# # load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# result = loaded_model.score(X_test, Y_test)\n",
    "# print(result)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#MinMaxScaler\n",
    "\n",
    "# scaler.fit(df_done_tasks_5_ml['TTC'])\n",
    "# df_done_tasks_5_ml['TTC_aft'] = scaler.transform(df_done_tasks_5_ml['TTC_aft'])\n",
    "# df['Col1_scaled'] = scaler.fit_transform(df['Col1'].values.reshape(-1,1))\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# X_copy = X.copy()\n",
    "# scaler = MinMaxScaler()\n",
    "# X_copy[['preg', 'plas']] = scaler.fit_transform(X_copy[['preg', 'plas']])\n",
    "# X_copy.head()\n",
    "# mydata[['x1','x2','x3']] = MinMaxScaler().fit_transform(mydata[['x1','x2','x3']])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
